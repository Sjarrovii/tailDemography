---
title: "Merge and Map"
author: "Christopher Agard, George Middendorf, and Andres Roubicek"
date: "September 3, 2017"
output:
  html_document: default
---
# Setting up R to run the script
```{r setup, include=FALSE}
rm(list=ls()) #clears the environment
# filefolder="G:/Lizard work for the road/excel files"
filefolder="C:/Users/test/Documents/Chris/Research/Sceloporus/Caudal Autotomy/Demography"
knitr::opts_knit$set(root.dir = normalizePath(filefolder)) 
#this is an option we have to use for RMD notebooks otherwise the wd is reset after each chunk is executed
#setwd(filefolder) #this can be used instead for a regular rscript
options(pkgType = "source")
mypackages=c("rio","ggplot2","stringr","tables","knitr","xlsx","rJava") 
neededpackages=mypackages[which(!is.element(el=mypackages,set=installed.packages()))]
if(length(neededpackages>0)){
    install.packages(neededpackages)
}else{
    warning("All packages already installed")
}
lapply(mypackages,function(x) library(x,character.only = T))
```

# Getting and Merging the Data
## Getting the Data
Next we must read the .xls and .xlsx files into r.  Since each file may have a different number of columns and different column headers, we cannot simply import them as a data frame.  Instead we will read each file into r as a separate element of a list *mydata*.
```{r}
myfiles<-list.files( path = "excelFiles",pattern = c(".xls",".xlsx"))
myfiles_path<-lapply(myfiles,function(x)paste("excelFiles",x,sep = "/"))
# mydata<-lapply(myfiles_path,function(x) read.xlsx2(x,sheetIndex = 1,colClasses = "character"))
mydata<-lapply(myfiles_path,function(x) read.xlsx2(x,sheetIndex = 1,colClasses = "character"))
```

## cleaning the Data
Now that the data have been read into R as elements in the list *mydata*, we need to:
FIX this - update the text below.
-*remove empty columns*
-*standardize variable names*
  --*change all column names and entries to lowercase
-*flag data that require review*
-*flag data to facilitate removal* [FIX THIS-This step should be moved to Lizard Reduce script]
-*move data to a data frame for analysis*

## Remove Empty Columns
I'm not sure why this happens, but calling the "read.xslx" resulted in a list a of data frames that each have several  empty columns at the end of the file.  There may be a way to fix this in the import, but I don't know what that is.  We can remove this step if that issue is ever resolved.
There are two programmatic ways that I can think to proceed here: 
1-*Create an index of empty columns for a file and use this to trim the data frame and apply this proceedure across all elements of the list.* This is the option I would prefer since it is the most flexible and the least likely to result in accidental data loss and I think would be the most elegant solution. We will however lose any column that contains no data, but either appproach bears this risk.
        - for this approach we will create a function to determine if a column is empty and if the name of the column contains "NA." The function will return a negative index that identifies those columns. If no such columns exist, the formula returns a vector of interger from 1 to the length of the dataset supplied to the function.
```{r}
emptyCol<-function(column){
        NAS<-apply(column,2,function(x) sum(is.na(x))/length(x))#number of NA values
        NAS<-which(NAS==1)
        NAnames<-grep(pattern = "NA.",x = names(column),ignore.case = T)
        result<-intersect(NAS,NAnames)
        if(length(result)==0){
                return(1:length(column))
        }else{
                return(-result)
        }
}
```
then we will apply this to the full list of data.
```{r, include=FALSE}
mydata_trim<-lapply(mydata,function(x) x[,emptyCol(x)])
print(lapply(mydata_trim,names))
```
2-*Since the empty data columns appear to be added to the end of the file, search through the a data frame for the first instance of an empty column and trimming the data frame to only include columns with an index smaller than that of the first empty column.* This could lead to data loss if the data frame has any empty columns inserted between columns with data.  We could add a bit of security by checking for the first instance of two consecutive empty columns. It is less likely, but the insertion of 2 consecutive empty columns between columns containing data.  
        -For now, unless we have reason to tackle this, we won't develop this approach.      
## Standardize variable names
### Change all column names to lowercase.
```{r, include=FALSE}
for(i in 1:length(mydata)){ #change all colnames to lowercase
  names(mydata_trim[[i]])<-tolower(names(mydata_trim[[i]]))
}
```
### Handle "tl"and "rtl"
First we'll have to standardize the names of the "tl" and "rtl" columns.  First we will search for colnames containing "rtl" and temporarily change them to "rxl".  
```{r}
rxl<-lapply(mydata_trim,function(x) grep(pattern = "rtl", x = names(x),ignore.case = T))
for(i in 1:length(rxl)){
        names(mydata_trim[[i]])[rxl[[i]]]<-"rxl"
}
```
Next we will search for all colnames containing "tl" and change them to "tl".
```{r}
tl<-lapply(mydata_trim,function(x) grep(pattern = "tl", x = names(x),ignore.case = T))
for(i in 1:length(tl)){
        names(mydata_trim[[i]])[tl[[i]]]<-"tl"
}
```
Then we will change all colnames "rxl" to "rtl".
```{r}
for(i in 1:length(mydata_trim)){
        names(mydata_trim[[i]])[which(names(mydata_trim[[i]])=="rxl")]<-"rtl"
}
```
### Standardize remaining variable names
Next we need to drop extraneous variables.  By extraneous, we mean those variables (column headings) which are not common across files to a particular year. We will achieve this by first creating a character vector populated with the names of the variables we wish to keep and converting it a single string vector of the same names separated by "|". That string will be used to identify variables which should be excluded or kept. 

This portion renames/standardizes variable names which we wish to keep. *Note: This code needs to to have *replace_names* supplied by hand.*
```{r, include=TRUE}
keepnames<-c("species", "toes","date","sex","svl","mass","paint.mark","location","meters","new.recap","vial","painted","misc")
tl_rtl<-"tl|rtl"
#removed "tl" and "rtl" from this b/c they were treated earlier and including them here changes them all to "tl".
p.keepnames<-c()
for(name in keepnames){p.keepnames<-paste(p.keepnames,name,"|",sep = "")}
p.keepnames<-substr(p.keepnames,1,nchar(p.keepnames)-1) #removes trailing "|".
rawnames<-lapply(mydata_trim,names)#original names for each year's data
mydata_vars<-list()#will eventually only contain columns with variable names that can be kept or fixed
droppedvar<-list() #Will eventually only contain variables dropped from mydata to create mydata_goodNames
for(i in 1:length(rawnames)){
    for(j in 1:length(rawnames[[i]])){
            if(length(grep(pattern = "tl|rtl",x=rawnames[[i]][j]))>0){
                    next()
            }
            if(length(grep(pattern = p.keepnames,x=rawnames[[i]][j])>0)){
                    for(name in keepnames){
                            if(length(grep(pattern= name,x=rawnames[[i]][j]))>0){
                                    rawnames[[i]][j]<-name
                            }
                    }
            }else{
                    rawnames[[i]][j]<-"DROP"
            }
    }
        droppedvar[[i]]<-mydata_trim[[i]][,which(rawnames[[i]]=="DROP")]#creates new list with dropped variables
        names(droppedvar[[i]])<-rawnames[[i]][which(rawnames[[i]]=="DROP")]#attaches names to droppedvar
        mydata_vars[[i]]<-mydata_trim[[i]][,which(rawnames[[i]]!="DROP")]#creates new list with kept variables
        names(mydata_vars[[i]])<-rawnames[[i]][which(rawnames[[i]]!="DROP")]#attaches mapped names to mydata_vars
}
```
### Add in "year" variable
Now we name add the variable year to each element of the list according the year of data that each element contains.
```{r}
myxls=list.files(path = "C:/Users/test/Documents/Chris/Research/Sceloporus/Caudal Autotomy/Demography/excelFiles",pattern="x.xls")
myyears<-strsplit(x=myxls,split = "xCC|x.xls")#creates a vector of the years for the data
myyears<-sapply(myyears,function(x) x[2])

#creates a variable, year, in each sublist of mydata_vars and populates it with the appropriate year from myyears
for(i in 1:length(mydata_vars)){
        mydata_vars[[i]][,"year"]<-myyears[i]
        }
```
## Move data to a data frame for analysis
Now we create a data frame, mycombfile on which analyses will be conducted and reclassify the appropriate variables as numeric variable.  For some reason, they were classified as character vectors during the population of the data.frame.
First, we will coerce all data to character class to facilitate the merge.  This step can probably be dropped, if the source files have consistent formatting for similar columns.  We will create a function to do this and then apply the function to each level in the list (i.e. each year)
```{r}
forceChar<-function(x){
        if(is.data.frame(x)==T){
                apply(x,2,as.character)
        }else{
                as.character(x)
        }
}
mydata_vars<-lapply(mydata_vars,forceChar)
```
Then we will merge the elements of mydata_vars into a single data frame and force "year" to integer.
```{r}
mycombfile<-data.frame()
for(i in 1:length(mydata_vars)){
    mycombfile<-rbind(mycombfile,mydata_vars[[i]])
}
```
# A few more cleaning and mapping steps:
-*Standardizing values in sex, species, painted, and new.recap*
-*Redefine rtl* 
-*Convert blanks to NA in all columns*
-*create tailcondition*
-*create toesbin
-*Identify data for review*
-*Identify data to be dropped* 
## Standardize values in sex, species, painted, and new.recap
First, we'll change all entries in sex, species, painted, and new.recap to lowercase.
```{r}
lowerCols<-grep("sex|species|painted|new.recap|toes",names(mycombfile))
for(col in lowerCols){
        mycombfile[,col]<-tolower(mycombfile[,col])
}
```
## Redefine rtl
Change rtl to rtl_orig and create 2 new columns:
- a new rtl column that only records how much tail has regrown (i.e. an intact animal and an animal which had autotmized, but has not regrown any tail would both have a value of 0 in this new rtl column)
- a autotmized column that indicates if the tail shows signs of ever having autotomized any amount (i.e. both autotomized animals with and without any regrown would have a value of TRUE here, while intact animals would have a value of FALSE)
```{r}
trim <- function (x) gsub("^\\s+|\\s+$", "", x)# from Stackoverflow https://stackoverflow.com/questions/2261079/how-to-trim-leading-and-trailing-whitespace-in-r
names(mycombfile)[which(names(mycombfile)=="rtl")]<-"rtl_orig"
mycombfile$rtl<-as.numeric(as.character(trim(trim(mycombfile$rtl_orig))))
mycombfile[which(mycombfile$rtl==-1),"rtl"]<-0
mycombfile$autotomized<-logical(nrow(mycombfile))
mycombfile[which(!is.na(mycombfile$rtl_orig) & mycombfile$rtl_orig!="o" & mycombfile$rtl_orig!="0" & mycombfile$rtl_orig!=" 0"),"autotomized"]<-T #don't know why I have to explicitly exclude rtl_orig =" 0" after using trim function
unique(mycombfile[which(mycombfile$autotomized==T),"rtl_orig"])
```
Change "new.recap" to "new.recap_orig" and create two new columns: "sighting" (character vector which is "sighting" if the encounter was a sighting and NA otherwise) and "new.recap" (a character vector that returns the value of new.recap_orig if "sighting"==TRUE.
```{r}
mycombfile$new.recap_orig<-mycombfile$new.recap
mycombfile$sighting<-rep(NA,nrow(mycombfile))
mycombfile[which(mycombfile$new.recap=="visual recapture" | mycombfile$new.recap=="sighting" | mycombfile$new.recap=="sighted"|mycombfile$sighing=="sighted"),"sighting"]<-"sighting"
mycombfile[which(mycombfile$sighting==T),"new.recap"]<-NA 
```
## Convert blanks to NA in all columns
First create function that converts blank cells to NA
```{r}
blank2NA<-function(x){
        x[which(as.character(x)=="")]<-NA
        return(as.character(x))
}
```
Then apply that function to the columns in mycombfile
```{r}
mycombfile<-as.data.frame(sapply(mycombfile,blank2NA))
```
## Create tailcondition
```{r}
#Resume Here
```
## Identify data for review
[sex values "male|female"->"m|f", species values "j|v"->"sj|sv", painted values "painted|yes" -> "P" and "[blank]|no" -> "N", new.recap values "new|n"->"N" and "recap|r"->"R".]
```{r}
#Make this into a more versatile function eventually
myfilters<-function(){
        mycombfile$review_sex<-logical(nrow(mycombfile))
        mycombfile[which((mycombfile$sex!="m" & mycombfile$sex!="f") & (mycombfile$forceFemale!=T & mycombfile$forceMale!=T)),"review_sex"]<-T
        mycombfile$review_species<-logical(nrow(mycombfile))
        mycombfile[grep("\\?",mycombfile$species),"review_species"]<-T 
        mycombfile$review_painted<-logical(nrow(mycombfile))
        mycombfile[which(mycombfile$painted!="painted" & mycombfile$painted!="yes" & mycombfile$painted!="" & mycombfile$painted!="no"),"review_painted"]<-T
        mycombfile$review_new.recap<-logical(nrow(mycombfile))
        mycombfile[which(mycombfile$new.recap!="new" & mycombfile$new.recap!="n" & mycombfile$new.recap!="recap" & mycombfile$painted!="r"),"review_new.recap"]<-T
        mycombfile$review_rtl<-logical(nrow(mycombfile))
        mycombfile[which(is.na(mycombfile$rtl) & !is.na(mycombfile$rtl_orig)),"review_rtl"]<-T
        return(mycombfile)
}
mycombfile<-myfilters()
```
#Reviewing filters
- The values here can help us to determine observations that don't need to be reviewed individually
```{r}
#make this a proper function eventually
review.filters<-function(){
        review_sex_values<-unique(mycombfile[which(mycombfile$review_sex==T),"sex"])
        review_species_values<-unique(mycombfile[which(mycombfile$review_species==T),"species"])
        review_painted_values<-unique(mycombfile[which(mycombfile$review_painted==T),"painted"])
        review_new.recap_values<-unique(mycombfile[which(mycombfile$review_new.recap==T),"new.recap"])
        review_rtl_values<-unique(mycombfile[which(mycombfile$review_rtl==T),"rtl_orig"])#fix this 
        review_sex_values<-data.frame("value"=unique(mycombfile[which(mycombfile$review_sex==T),"sex"]),"nchar"=nchar(as.character(review_sex_values)))
        review_species_values<-data.frame("value"=unique(mycombfile[which(mycombfile$review_species==T),"species"]),"nchar"=nchar(as.character(review_species_values)))
        review_painted_values<-data.frame("value"=unique(mycombfile[which(mycombfile$review_painted==T),"painted"]),"nchar"=nchar(as.character(review_painted_values)))
        review_new.recap_values<-data.frame("value"=unique(mycombfile[which(mycombfile$review_new.recap==T),"new.recap"]),"nchar"=nchar(as.character(review_new.recap_values)))
        review_rtl_values<-data.frame("value"=unique(mycombfile[which(mycombfile$review_rtl==T),"rtl"]),"nchar"=nchar(as.character(review_rtl_values)))
        filter_review<-list("sex"=review_sex_values,"species"=review_species_values,"painted"=review_painted_values,"new.recap"=review_new.recap_values,"rtl"=review_rtl_values)
        filter_review<-list("sex"=review_sex_values,"species"=review_species_values,"new.recap"=review_new.recap_values,"rtl"=review_rtl_values)
        return(filter_review)
}
filter_review<-review.filters()
```
#Make fixes based on filter review
```{r}
mycombfile$forceMale<-logical(nrow(mycombfile))
mycombfile[which(mycombfile$sex=="m "|mycombfile$sex=="male"),"forceMale"]<-T
mycombfile$forceFemale<-logical(nrow(mycombfile))
mycombfile[which(mycombfile$sex=="f "),"forceFemale"]<-T
mycombfile$forceRecap<-logical(nrow(mycombfile))
mycombfile[which(mycombfile$new.recap=="recap " | mycombfile$new.recap=="reecap" |mycombfile$new.recap=="recapq"| mycombfile$new.recap=="r"),"forceRecap"]<-T
mycombfile$forceNew<-logical(nrow(mycombfile))
mycombfile[which(mycombfile$new.recap=="new "),"forceNew"]<-T

#REsume here - apply the above filters to force changes ]
```
## Identify data to be dropped
Here we identify unwanted data and flagging:
    -species (those other than Sj and Sv)
    -those which do not have data for critical variables (species, svl, tl, rtl, toes)
```{r}
mycombfile$drop_species<-logical(nrow(mycombfile))
mycombfile[which((substr(mycombfile$species,1,1)!="v" & (substr(mycombfile$species,1,1)!="j")& (substr(mycombfile$species,1,1)!="s"))| (substr(mycombfile$species,1,2)=="sc")| (substr(mycombfile$species,1,2)=="sn")),"drop_species"]<-T
mycombfile[grep("\\?",mycombfile$species),"drop_species"]<-F
unique(mycombfile[which(mycombfile$drop_species==T),"species"])
mycombfile$drop_morphometrics<-logical(nrow(mycombfile))
mycombfile[which(is.na(mycombfile$species)|is.na(mycombfile$svl)|is.na(mycombfile$tl)|is.na(mycombfile$rtl_orig)|is.na(mycombfile$toes)),"drop_morphometrics"]<-T
```
## Create toesbin
We also handle data for toes:
    -where a letter was included in the entry to distinguish separate animals with the same toes removed. We do this by capturing the letter in a new variable, unique_id, and removing the letter from the toes column.
    -special characters and leading spaces or single quotes in toe data are removed
    -a character vector of binary representation of toe clip marking is generated from cleaned toes

```{r}
#FIX THIS
```

# Export mapped dataframe
```{r}
write.xlsx2(mycombfile,"mapped data.xlsx",showNA=T)
```
