{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Data (Part 1)\n",
    "The purpose of this notebook is to read in raw excel data for multiple years, append them into a single dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='TOC'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "1. [Setting up Python](#SettingUp)\n",
    "    \n",
    "    a. [Setting the Location](#SettingLoc)\n",
    "    \n",
    "    b. [Importing Necessary Packages](#ImportingPackages)\n",
    "    \n",
    "    b. [Getting Data](#GettingData)\n",
    "    \n",
    "    c. [Preparing for a Save](#PreparingSave)\n",
    "    \n",
    "\n",
    "2. [Reading in Data](#ReadingData)\n",
    "\n",
    "3. [Cleaning Data](#CleaningData)\n",
    "\n",
    "4. [Appending Data](#AppendingData)\n",
    "\n",
    "5. [Exporting Data](#ExportingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='SettingUp'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up Python\n",
    "[Top](#TOC)\n",
    "\n",
    "[Setting the Location](#SettingLoc)\n",
    "    \n",
    "[Importing Necessary Packages](#ImportingPackages)\n",
    "    \n",
    "[Getting Data](#GettingData)\n",
    "    \n",
    "[Preparing for a Save](#PreparingSave)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ImportingPackages'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Necessary Packages\n",
    "\n",
    "[Top](#TOC)\n",
    "\n",
    "[Setting Up Python](#SettingUp)\n",
    "\n",
    "Here we import necessary packages. \n",
    "This chunk may take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob,os\n",
    "from liz_number import lizsort,mindate,smallest,validate\n",
    "from liz_toes import make_str,label_pattern, replace_pattern,report_pattern\n",
    "\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "plotly.tools.set_config_file(world_readable=True)\n",
    "\n",
    "# increase print limit\n",
    "pd.options.display.max_rows = 99999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='SettingLoc'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the Location\n",
    "[Top](#TOC)\n",
    "\n",
    "[Setting Up Python](#SettingUp)\n",
    "\n",
    "These chunks identify the locations from which we can get data and to which we can save data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source Data\n",
    "Raw data can be found in the following locations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sourceDataPers = 'C:/Users/Christopher/Google Drive/TailDemography/outputFiles'\n",
    "sourceDataBig = 'S:/Chris/TailDemography/TailDemography/Raw Data'\n",
    "# sourceBlack = 'C:/Users/test/Desktop'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we change the working directory to the source path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(sourceDataBig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Data\n",
    "The cleaned data will be saved to one of these locations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputPers = 'C:/Users/Christopher/Google Drive/TailDemography/outputFiles'\n",
    "outputBig = 'S:/Chris/TailDemography/TailDemography/Cleaned Combined Data'\n",
    "# outputBlack = 'C:/Users/test/Desktop'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ImportingData'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Data\n",
    "[Top](#TOC)\n",
    "\n",
    "[Setting up Python](#SettingUp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use search the source path to locate and eventually read the raw data into our notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CC 2000-03-modified from CC-SJ 00-03 final.xls',\n",
       " 'CC 2004.xlsx',\n",
       " 'CC 2015 - captures.xls',\n",
       " 'CC 2016 - captures.xls',\n",
       " 'CC 2017 Lizards - 3viii17 captures and obs.xls',\n",
       " 'xCC2005x.xls',\n",
       " 'xCC2006x.xls',\n",
       " 'xCC2007x.xls',\n",
       " 'xCC2008x.xls',\n",
       " 'xCC2009x.xls',\n",
       " 'xCC2010x.xlsx',\n",
       " 'xCC2011x.xls',\n",
       " 'xCC2012x.xls',\n",
       " 'xCC2013x.xls',\n",
       " 'xCC2014x.xlsx']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawfiles = glob.glob('*.xls*')\n",
    "rawfiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect these data.  We will begin by looking at the number of columns and rows. In each file. To do this first we define a function, *xlsheets*, which we define below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xlsheets(file):\n",
    "    \"\"\"The function takes a string, *file*, and returns the number and names of sheets in that file.\\\n",
    "    The function relies on the pandas package.\"\"\"\n",
    "    tmp = pd.ExcelFile(file)\n",
    "    res = {'num_sheets':len(tmp.sheet_names),'names': tmp.sheet_names}\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that when we call *xlsheets* on the first file in our list of files, it returns the total number of sheets and names of each sheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_sheets': 4, 'names': ['2000', '2001', '2002', '2003']}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xlsheets(rawfiles[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will apply this to all of the files in raw files to inspect the data at the highest level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     {'num_sheets': 4, 'names': ['2000', '2001', '2...\n",
       "1                 {'num_sheets': 1, 'names': ['2004 ']}\n",
       "2                  {'num_sheets': 1, 'names': ['2015']}\n",
       "3                  {'num_sheets': 1, 'names': ['2016']}\n",
       "4                  {'num_sheets': 1, 'names': ['2017']}\n",
       "5                  {'num_sheets': 1, 'names': ['2005']}\n",
       "6                  {'num_sheets': 1, 'names': ['2006']}\n",
       "7        {'num_sheets': 2, 'names': ['Sheet1', '2007']}\n",
       "8                  {'num_sheets': 1, 'names': ['2008']}\n",
       "9                  {'num_sheets': 1, 'names': ['2009']}\n",
       "10               {'num_sheets': 1, 'names': ['Sheet1']}\n",
       "11               {'num_sheets': 1, 'names': ['Sheet1']}\n",
       "12                 {'num_sheets': 1, 'names': ['data']}\n",
       "13         {'num_sheets': 1, 'names': ['CC 2013 data']}\n",
       "14                 {'num_sheets': 1, 'names': ['2014']}\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(rawfiles).apply(xlsheets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need to treat the 1st and 8th files in the source data differently when we read in the data.  Let's group the file names accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawfiles_ms = [rawfiles[0],rawfiles[7]]\n",
    "rawfiles_ss = list(set(rawfiles)- set(rawfiles_ms))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The names of files with multiple sheets are now in the variable *rawfiles_ms*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CC 2000-03-modified from CC-SJ 00-03 final.xls', 'xCC2007x.xls']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawfiles_ms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The names of files with a single sheet are now in the variable *rawfiles_ss*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xCC2010x.xlsx',\n",
       " 'CC 2017 Lizards - 3viii17 captures and obs.xls',\n",
       " 'xCC2012x.xls',\n",
       " 'xCC2008x.xls',\n",
       " 'xCC2011x.xls',\n",
       " 'xCC2006x.xls',\n",
       " 'CC 2016 - captures.xls',\n",
       " 'CC 2004.xlsx',\n",
       " 'xCC2009x.xls',\n",
       " 'xCC2005x.xls',\n",
       " 'xCC2013x.xls',\n",
       " 'CC 2015 - captures.xls',\n",
       " 'xCC2014x.xlsx']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawfiles_ss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a look at the number of columns in each file. We'll start with the single sheet files, since this is the easiest.  We will define another function, *xlcolshape* to make this easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xlcolshape(file):\n",
    "    \"\"\"xlcolshape takes a file name as a string and returns the shape of the excel file\"\"\"\n",
    "    return pd.read_excel(file).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we call this function on the first of the single-sheet files, we can see that it returns a tuple in the format ('number of rows', 'number of columns')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99, 41)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xlcolshape(rawfiles_ss[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will apply this funtion to the list of single-sheet files for our inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      (99, 41)\n",
       "1     (798, 21)\n",
       "2      (85, 19)\n",
       "3     (134, 20)\n",
       "4      (64, 19)\n",
       "5     (163, 16)\n",
       "6     (103, 21)\n",
       "7     (479, 16)\n",
       "8     (162, 16)\n",
       "9     (202, 16)\n",
       "10    (106, 19)\n",
       "11    (241, 19)\n",
       "12     (97, 19)\n",
       "dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(rawfiles_ss).apply(xlcolshape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='HandlingColumns'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Columns\n",
    "[Top](#TOC)\n",
    "\n",
    "[Importing Data](#ImportingData)\n",
    "\n",
    "We don't have to look in the multiple-sheet file.  It's clear that we'll have to identify a common set of columns prior to combining these files.  Let's define a few functions to help us do this.\n",
    "\n",
    "We will want to do the following:\n",
    "1. [build a list of unique column names](#FindUniqueCol)\n",
    "2. [eliminate unnecessary columns](#DropCol)\n",
    "3. [combine synonyms ](#CombineCol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='FindUniqueCol'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding Unique Columns\n",
    "[Top](#TOC)\n",
    "\n",
    "[Importing Data](#ImportingData)\n",
    "\n",
    "[Handling Columns](#HandlingColumns)\n",
    "\n",
    "We'll define a function to extract column names and convert them to a set we'll use that function to allow us to only add unique names to a list of column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xluniquecol(file,sheet=0):\n",
    "    \"\"\"xluniquecol takes a string filename of an excel file and extracts the column names as a set.\"\"\"\n",
    "    return list(pd.read_excel(file,sheet_name=sheet).columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of how xluniquecol works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['species',\n",
       " 'TOES',\n",
       " 'date',\n",
       " 'sex',\n",
       " 'SVL (mm)',\n",
       " 'TL (mm)',\n",
       " 'RTL (mm)',\n",
       " 'Tail condition (1=intact; 2=autotomized; 3=regrown)',\n",
       " 'mass (g)',\n",
       " 'paint mark',\n",
       " 'location',\n",
       " 'meters',\n",
       " 'NEW/recap',\n",
       " 'painted or not',\n",
       " 'misc/notes',\n",
       " 'Collectors',\n",
       " 'VIAL',\n",
       " 'TIME',\n",
       " 'Toe 1',\n",
       " 'Toe 2',\n",
       " 'Toe 3',\n",
       " 'Toe 4',\n",
       " 'Toe 5',\n",
       " 'Toe 6',\n",
       " 'Toe 7',\n",
       " 'Toe 8',\n",
       " 'Toe 9',\n",
       " 'Toe 10',\n",
       " 'Toe 11',\n",
       " 'Toe 12',\n",
       " 'Toe 13',\n",
       " 'Toe 14',\n",
       " 'Toe 15',\n",
       " 'Toe 16',\n",
       " 'Toe 17',\n",
       " 'Toe 18',\n",
       " 'Toe 19',\n",
       " 'Toe 20',\n",
       " 'Year',\n",
       " '1st Capture (year)',\n",
       " 'Years Alive (known)']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xluniquecol(rawfiles_ss[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will create an empty set, *uniquecols*, that will eventually contain the unique column names in all of the files.\n",
    "\n",
    "We will append the unique column names from each file to *uniquecols*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1,\n",
       " 'painted',\n",
       " 'Unnamed: 19',\n",
       " 'Toe 13',\n",
       " 'Tail condition (1=intact; 2=autotomized; 3=regrown)',\n",
       " 'Toe 11',\n",
       " 'Toes',\n",
       " 'misc/notes',\n",
       " 'Mark',\n",
       " 'Toe 2',\n",
       " '2015 or earlier',\n",
       " 'misc',\n",
       " '1st Capture (year)',\n",
       " 'Year',\n",
       " 'mass',\n",
       " 'Toe 8',\n",
       " 'Painted',\n",
       " 'Toe 15',\n",
       " 'Toe 1',\n",
       " 'Toe 6',\n",
       " 'Toe 7',\n",
       " 'Toe 12',\n",
       " 'Toe 18',\n",
       " 'Misc.',\n",
       " 'date',\n",
       " 'RTL',\n",
       " 'location',\n",
       " 'Toe 16',\n",
       " 'Sex',\n",
       " 'Spotted',\n",
       " 'Toe 3',\n",
       " 'TL (mm)',\n",
       " 'Time',\n",
       " 'Date',\n",
       " 'TOES',\n",
       " 'species',\n",
       " 'TL',\n",
       " 'New/Recap',\n",
       " 'Species',\n",
       " 'painted or not',\n",
       " 'Toe 17',\n",
       " 'Years Alive (known)',\n",
       " 'Meters',\n",
       " 'Vial',\n",
       " 'sex',\n",
       " 'RTL (mm)',\n",
       " 'mass (g)',\n",
       " 'meters',\n",
       " 'VIAL',\n",
       " 'Toe 14',\n",
       " 'NEW/recap',\n",
       " 'TIME',\n",
       " 'Paint Mark',\n",
       " 'Marked',\n",
       " 'SVL (mm)',\n",
       " 'Toe 9',\n",
       " 'Toe 10',\n",
       " 'Unnamed: 17',\n",
       " 'Toe 4',\n",
       " 'Location',\n",
       " 'Collectors',\n",
       " 'Toe 20',\n",
       " 'Unnamed: 16',\n",
       " 'Toe 5',\n",
       " 'SVL',\n",
       " 'Toe 19',\n",
       " 'Mass',\n",
       " ' painted or not',\n",
       " 'paint mark']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = pd.Series(rawfiles_ss).apply(xluniquecol)\n",
    "uniquecols = list()\n",
    "for u in tmp:\n",
    "    uniquecols = uniquecols+u\n",
    "uniquecols = list(set(uniquecols))\n",
    "uniquecols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='CombineCol'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining Synonymns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have identified the columns we need to keep, we'll need to apply this list to the files as they are read into python by doing the following:\n",
    "1. [rename wanted columns according to the common list](#Rename)\n",
    "2. [drop unwanted columns](#Drop)\n",
    "3. [append the renamed and trimmed dataframes together to form a combined dataframe](#Append)\n",
    "4. [save that combined dataframe to the archive](#SaveCombined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "keepCol = ['species', 'date', 'sex', 'svl', 'tl', 'rtl', 'mass',\n",
    "       'paint.mark', 'location', 'meters', 'new.recap', 'painted', 'misc',\n",
    "       'vial', 'year', 'autotomized', 'sighting', 'toes']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a function to identify potential synonyms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Series' object has no attribute 'to_list'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-114-ece818999b61>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniquecols\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontains\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeepCol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_list\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0midx\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   4370\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_info_axis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_can_hold_identifiers_and_holds_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4371\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4372\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4373\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4374\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'Series' object has no attribute 'to_list'"
     ]
    }
   ],
   "source": [
    "idx = pd.Series(uniquecols).str.lower().str.contains(pd.Series(keepCol).str.lower()[0])\n",
    "idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='DropCol'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminate Unnecessary Columns\n",
    "[Top](#TOC)\n",
    "\n",
    "[Importing Data](#ImportingData)\n",
    "\n",
    "[Handling Columns](#HandlingColumns)\n",
    "\n",
    "Now we will try to identify unnecessary columns and eliminate them. Much of this will be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'autotomized', 'new.recap', 'paint.mark', 'sighting'}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(pd.Series(keepCol).str.lower())-set(pd.Series(uniquecols).str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' painted or not',\n",
       " '1st capture (year)',\n",
       " '2015 or earlier',\n",
       " 'collectors',\n",
       " 'mark',\n",
       " 'marked',\n",
       " 'mass (g)',\n",
       " 'misc.',\n",
       " 'misc/notes',\n",
       " nan,\n",
       " 'new/recap',\n",
       " 'paint mark',\n",
       " 'painted or not',\n",
       " 'rtl (mm)',\n",
       " 'spotted',\n",
       " 'svl (mm)',\n",
       " 'tail condition (1=intact; 2=autotomized; 3=regrown)',\n",
       " 'time',\n",
       " 'tl (mm)',\n",
       " 'toe 1',\n",
       " 'toe 10',\n",
       " 'toe 11',\n",
       " 'toe 12',\n",
       " 'toe 13',\n",
       " 'toe 14',\n",
       " 'toe 15',\n",
       " 'toe 16',\n",
       " 'toe 17',\n",
       " 'toe 18',\n",
       " 'toe 19',\n",
       " 'toe 2',\n",
       " 'toe 20',\n",
       " 'toe 3',\n",
       " 'toe 4',\n",
       " 'toe 5',\n",
       " 'toe 6',\n",
       " 'toe 7',\n",
       " 'toe 8',\n",
       " 'toe 9',\n",
       " 'unnamed: 16',\n",
       " 'unnamed: 17',\n",
       " 'unnamed: 19',\n",
       " 'years alive (known)'}"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(pd.Series(uniquecols).str.lower())-set(pd.Series(keepCol).str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since data for years 2000-2003 are contained in the same Excel file we will have to treat this file differently than the others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='PreparingSave'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing for a Save\n",
    "[Top](#TOC)\n",
    "\n",
    "[Setting up Python](#SettingUp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ReadingData'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading in Data\n",
    "[Top](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='CleaningData'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Data\n",
    "[Top](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='AppendingData'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appending Data\n",
    "[Top](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ExportingData'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting Data\n",
    "[Top](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
