{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Data (Part 1)\n",
    "The purpose of this notebook is to read in raw excel data for multiple years, append them into a single dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='TOC'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "1. [Setting up Python](#SettingUp)\n",
    "    \n",
    "    a. [Setting the Location](#SettingLoc)\n",
    "    \n",
    "    b. [Importing Necessary Packages](#ImportingPackages)\n",
    "    \n",
    "    c. [Preparing for a Save](#PreparingSave)\n",
    "    \n",
    "\n",
    "2. [Reading in Data](#ReadingData)\n",
    "\n",
    "3. [Cleaning Data](#CleaningData)\n",
    "\n",
    "4. [Appending Data](#AppendingData)\n",
    "\n",
    "5. [Exporting Data](#ExportingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='SettingUp'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up Python\n",
    "[Top](#TOC)\n",
    "\n",
    "[Setting the Location](#SettingLoc)\n",
    "    \n",
    "[Importing Necessary Packages](#ImportingPackages)\n",
    "    \n",
    "[Getting Data](#GettingData)\n",
    "    \n",
    "[Preparing for a Save](#PreparingSave)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ImportingPackages'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Necessary Packages\n",
    "\n",
    "[Top](#TOC)\n",
    "\n",
    "[Setting Up Python](#SettingUp)\n",
    "\n",
    "Here we import necessary packages. \n",
    "This chunk may take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob,os\n",
    "from liz_number import lizsort,mindate,smallest,validate\n",
    "from liz_toes import make_str,label_pattern, replace_pattern,report_pattern\n",
    "\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "plotly.tools.set_config_file(world_readable=True)\n",
    "\n",
    "# increase print limit\n",
    "pd.options.display.max_rows = 99999"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='PreparingSave'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing for a Save\n",
    "[Top](#TOC)\n",
    "\n",
    "[Setting up Python](#SettingUp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='SettingLoc'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the Location\n",
    "[Top](#TOC)\n",
    "\n",
    "[Setting Up Python](#SettingUp)\n",
    "\n",
    "These chunks identify the locations from which we can get data and to which we can save data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Source Data\n",
    "Raw data can be found in the following locations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sourceDataPers = 'C:/Users/Christopher/Google Drive/TailDemography/outputFiles'\n",
    "sourceDataBig = 'S:/Chris/TailDemography/TailDemography/Raw Data'\n",
    "# sourceBlack = 'C:/Users/test/Desktop'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we change the working directory to the source path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(sourceDataBig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output Data\n",
    "The cleaned data will be saved to one of these locations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outputPers = 'C:/Users/Christopher/Google Drive/TailDemography/outputFiles'\n",
    "outputBig = 'S:/Chris/TailDemography/TailDemography/Cleaned Combined Data'\n",
    "# outputBlack = 'C:/Users/test/Desktop'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ReadingData'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading in Data\n",
    "[Top](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use search the source path to locate and eventually read the raw data into our notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CC 2000-03-modified from CC-SJ 00-03 final.xls',\n",
       " 'CC 2004.xlsx',\n",
       " 'CC 2015 - captures.xls',\n",
       " 'CC 2016 - captures.xls',\n",
       " 'CC 2017 Lizards - 3viii17 captures and obs.xls',\n",
       " 'xCC2005x.xls',\n",
       " 'xCC2006x.xls',\n",
       " 'xCC2007x.xls',\n",
       " 'xCC2008x.xls',\n",
       " 'xCC2009x.xls',\n",
       " 'xCC2010x.xlsx',\n",
       " 'xCC2011x.xls',\n",
       " 'xCC2012x.xls',\n",
       " 'xCC2013x.xls',\n",
       " 'xCC2014x.xlsx']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawfiles = glob.glob('*.xls*')\n",
    "rawfiles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect these data.  We will begin by looking at the number of columns and rows. In each file. To do this first we define a function, *xlsheets*, which we define below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xlsheets(file):\n",
    "    \"\"\"The function takes a string, *file*, and returns the number and names of sheets in that file.\\\n",
    "    The function relies on the pandas package.\"\"\"\n",
    "    tmp = pd.ExcelFile(file)\n",
    "    res = {'num_sheets':len(tmp.sheet_names),'names': tmp.sheet_names}\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can see that when we call *xlsheets* on the first file in our list of files, it returns the total number of sheets and names of each sheet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'num_sheets': 4, 'names': ['2000', '2001', '2002', '2003']}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xlsheets(rawfiles[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will apply this to all of the files in raw files to inspect the data at the highest level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     {'num_sheets': 4, 'names': ['2000', '2001', '2...\n",
       "1                 {'num_sheets': 1, 'names': ['2004 ']}\n",
       "2                  {'num_sheets': 1, 'names': ['2015']}\n",
       "3                  {'num_sheets': 1, 'names': ['2016']}\n",
       "4                  {'num_sheets': 1, 'names': ['2017']}\n",
       "5                  {'num_sheets': 1, 'names': ['2005']}\n",
       "6                  {'num_sheets': 1, 'names': ['2006']}\n",
       "7        {'num_sheets': 2, 'names': ['Sheet1', '2007']}\n",
       "8                  {'num_sheets': 1, 'names': ['2008']}\n",
       "9                  {'num_sheets': 1, 'names': ['2009']}\n",
       "10               {'num_sheets': 1, 'names': ['Sheet1']}\n",
       "11               {'num_sheets': 1, 'names': ['Sheet1']}\n",
       "12                 {'num_sheets': 1, 'names': ['data']}\n",
       "13         {'num_sheets': 1, 'names': ['CC 2013 data']}\n",
       "14                 {'num_sheets': 1, 'names': ['2014']}\n",
       "dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(rawfiles).apply(xlsheets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will need to treat the 1st and 8th files in the source data differently when we read in the data.  Let's group the file names accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawfiles_ms = [rawfiles[0],rawfiles[7]]\n",
    "rawfiles_ss = list(set(rawfiles)- set(rawfiles_ms))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The names of files with multiple sheets are now in the variable *rawfiles_ms*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['CC 2000-03-modified from CC-SJ 00-03 final.xls', 'xCC2007x.xls']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawfiles_ms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The names of files with a single sheet are now in the variable *rawfiles_ss*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xCC2009x.xls',\n",
       " 'xCC2012x.xls',\n",
       " 'xCC2011x.xls',\n",
       " 'xCC2014x.xlsx',\n",
       " 'xCC2008x.xls',\n",
       " 'xCC2006x.xls',\n",
       " 'CC 2015 - captures.xls',\n",
       " 'xCC2005x.xls',\n",
       " 'CC 2004.xlsx',\n",
       " 'CC 2016 - captures.xls',\n",
       " 'CC 2017 Lizards - 3viii17 captures and obs.xls',\n",
       " 'xCC2013x.xls',\n",
       " 'xCC2010x.xlsx']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rawfiles_ss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's take a look at the number of columns in each file. We'll start with the single sheet files, since this is the easiest.  We will define another function, *xlcolshape* to make this easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xlcolshape(file):\n",
    "    \"\"\"xlcolshape takes a file name as a string and returns the shape of the excel file\"\"\"\n",
    "    return pd.read_excel(file).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we call this function on the first of the single-sheet files, we can see that it returns a tuple in the format ('number of rows', 'number of columns')."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(162, 16)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xlcolshape(rawfiles_ss[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will apply this funtion to the list of single-sheet files for our inspection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     (162, 16)\n",
       "1      (85, 19)\n",
       "2      (64, 19)\n",
       "3      (97, 19)\n",
       "4     (134, 20)\n",
       "5     (163, 16)\n",
       "6     (241, 19)\n",
       "7     (202, 16)\n",
       "8     (479, 16)\n",
       "9     (103, 21)\n",
       "10    (798, 21)\n",
       "11    (106, 19)\n",
       "12     (99, 41)\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(rawfiles_ss).apply(xlcolshape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='CleaningData'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Data\n",
    "[Top](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='HandlingColumns'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling Columns\n",
    "[Top](#TOC)\n",
    "\n",
    "[Getting Data](#GettingData)\n",
    "\n",
    "We don't have to look in the multiple-sheet file.  It's clear that we'll have to identify a common set of columns prior to combining these files.  Let's define a few functions to help us do this.\n",
    "\n",
    "We will want to do the following:\n",
    "1. [build a list of unique column names](#FindUniqueCol)\n",
    "2. [eliminate unnecessary columns](#DropCol)\n",
    "3. [combine synonyms ](#CombineCol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='FindUniqueCol'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding Unique Columns\n",
    "[Top](#TOC)\n",
    "\n",
    "[Cleaning Data](#CleaningData)\n",
    "\n",
    "[Handling Columns](#HandlingColumns)\n",
    "\n",
    "We'll define a function to extract column names and convert them to a set we'll use that function to allow us to only add unique names to a list of column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xluniquecol(file,sheet=0):\n",
    "    \"\"\"xluniquecol takes a string filename of an excel file and extracts the column names as a set.\"\"\"\n",
    "    return list(pd.read_excel(file,sheet_name=sheet).columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example of how xluniquecol works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Species',\n",
       " 'Toes',\n",
       " 'Date',\n",
       " 'Sex',\n",
       " 'SVL',\n",
       " 'TL',\n",
       " 'RTL',\n",
       " 'Mass',\n",
       " 'Paint Mark',\n",
       " 'Location',\n",
       " 'Meters',\n",
       " 'New/Recap',\n",
       " ' painted or not',\n",
       " 'Misc.',\n",
       " 'Vial',\n",
       " 'Time']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xluniquecol(rawfiles_ss[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will create an empty set, *uniquecols*, that will eventually contain the unique column names in all of the files.\n",
    "\n",
    "We will append the unique column names from each file to *uniquecols*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RTL',\n",
       " 'Marked',\n",
       " 1,\n",
       " 'Toes',\n",
       " 'paint mark',\n",
       " 'Toe 20',\n",
       " 'Year',\n",
       " 'Paint Mark',\n",
       " 'SVL',\n",
       " 'Toe 12',\n",
       " 'Painted',\n",
       " 'species',\n",
       " 'Mark',\n",
       " 'Toe 15',\n",
       " 'Toe 8',\n",
       " 'Tail condition (1=intact; 2=autotomized; 3=regrown)',\n",
       " 'NEW/recap',\n",
       " 'SVL (mm)',\n",
       " '2015 or earlier',\n",
       " 'mass',\n",
       " 'TOES',\n",
       " 'Toe 10',\n",
       " 'Toe 16',\n",
       " 'sex',\n",
       " 'Mass',\n",
       " 'Meters',\n",
       " 'mass (g)',\n",
       " 'misc/notes',\n",
       " 'painted or not',\n",
       " 'Collectors',\n",
       " '1st Capture (year)',\n",
       " 'Toe 6',\n",
       " 'Species',\n",
       " ' painted or not',\n",
       " 'meters',\n",
       " 'Toe 2',\n",
       " 'painted',\n",
       " 'Toe 17',\n",
       " 'date',\n",
       " 'Toe 18',\n",
       " 'Location',\n",
       " 'Toe 3',\n",
       " 'Toe 9',\n",
       " 'misc',\n",
       " 'New/Recap',\n",
       " 'Toe 14',\n",
       " 'Years Alive (known)',\n",
       " 'Misc.',\n",
       " 'location',\n",
       " 'Toe 7',\n",
       " 'Toe 13',\n",
       " 'RTL (mm)',\n",
       " 'Date',\n",
       " 'Unnamed: 17',\n",
       " 'TL (mm)',\n",
       " 'Unnamed: 16',\n",
       " 'Toe 11',\n",
       " 'Spotted',\n",
       " 'TIME',\n",
       " 'Toe 1',\n",
       " 'Unnamed: 19',\n",
       " 'Toe 19',\n",
       " 'VIAL',\n",
       " 'Toe 5',\n",
       " 'TL',\n",
       " 'Sex',\n",
       " 'Time',\n",
       " 'Vial',\n",
       " 'Toe 4']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp = pd.Series(rawfiles_ss).apply(xluniquecol)\n",
    "uniquecols = list()\n",
    "for u in tmp:\n",
    "    uniquecols = uniquecols+u\n",
    "uniquecols = list(set(uniquecols))\n",
    "uniquecols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='DropCol'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminate Unnecessary Columns\n",
    "[Top](#TOC)\n",
    "\n",
    "[Cleaning Data](#CleaningData)\n",
    "\n",
    "[Handling Columns](#HandlingColumns)\n",
    "\n",
    "Now we will try to identify unnecessary columns and eliminate them. Much of this will be done manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "keepCol = ['species', 'date', 'sex', 'svl', 'tl', 'rtl', 'mass',\n",
    "       'paint.mark', 'location', 'meters', 'new.recap', 'painted', 'misc',\n",
    "       'vial', 'year', 'autotomized', 'sighting', 'toes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'autotomized', 'new.recap', 'paint.mark', 'sighting'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(pd.Series(keepCol).str.lower())-set(pd.Series(uniquecols).str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{' painted or not',\n",
       " '1st capture (year)',\n",
       " '2015 or earlier',\n",
       " 'collectors',\n",
       " 'mark',\n",
       " 'marked',\n",
       " 'mass (g)',\n",
       " 'misc.',\n",
       " 'misc/notes',\n",
       " nan,\n",
       " 'new/recap',\n",
       " 'paint mark',\n",
       " 'painted or not',\n",
       " 'rtl (mm)',\n",
       " 'spotted',\n",
       " 'svl (mm)',\n",
       " 'tail condition (1=intact; 2=autotomized; 3=regrown)',\n",
       " 'time',\n",
       " 'tl (mm)',\n",
       " 'toe 1',\n",
       " 'toe 10',\n",
       " 'toe 11',\n",
       " 'toe 12',\n",
       " 'toe 13',\n",
       " 'toe 14',\n",
       " 'toe 15',\n",
       " 'toe 16',\n",
       " 'toe 17',\n",
       " 'toe 18',\n",
       " 'toe 19',\n",
       " 'toe 2',\n",
       " 'toe 20',\n",
       " 'toe 3',\n",
       " 'toe 4',\n",
       " 'toe 5',\n",
       " 'toe 6',\n",
       " 'toe 7',\n",
       " 'toe 8',\n",
       " 'toe 9',\n",
       " 'unnamed: 16',\n",
       " 'unnamed: 17',\n",
       " 'unnamed: 19',\n",
       " 'years alive (known)'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(pd.Series(uniquecols).str.lower())-set(pd.Series(keepCol).str.lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since data for years 2000-2003 are contained in the same Excel file we will have to treat this file differently than the others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='CombineCol'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining Synonymous Columns\n",
    "[Top](#TOC)\n",
    "\n",
    "[Cleaning Data](#CleaningData)\n",
    "\n",
    "[Handling Columns](#HandlingColumns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have identified the columns we need to keep, we'll need to apply this list to the files as they are read into python by doing the following:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a function to identify potential synonyms. One approach is to take a column name that we want to keep and search through a list of names to identify any that contain enough of that name to be considered potentially synonymous.  Let's try to return these potential matches as values in a dictionary and return the desired name as the key for those values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def colmatchtodict(x,series, dictsource, key= None):\n",
    "    \"\"\"This takes a string, x, and a looks for values in a series that match that contain that string.\n",
    "    Those values which match are returned as values in a python dict for the key, key.\"\"\"\n",
    "    \n",
    "    assert isinstance(series,pd.Series)\n",
    "    if key is None:\n",
    "        key = x\n",
    "    tmp = series[series.astype(str).str.contains(x,case = False)].tolist()\n",
    "    dictsource[key] = tmp\n",
    "    return dictsource\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "coldict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'toes': ['Toes', 'TOES']}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "colmatchtodict('toes',pd.Series(uniquecols),coldict, key = 'toes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's see what happened when we apply this funtion to our, keepCol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "coldict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'species': ['species', 'Species'],\n",
       " 'date': ['date', 'Date'],\n",
       " 'sex': ['sex', 'Sex'],\n",
       " 'svl': ['SVL', 'SVL (mm)'],\n",
       " 'tl': ['RTL', 'RTL (mm)', 'TL (mm)', 'TL'],\n",
       " 'rtl': ['RTL', 'RTL (mm)'],\n",
       " 'mass': ['mass', 'Mass', 'mass (g)'],\n",
       " 'paint.mark': ['paint mark', 'Paint Mark'],\n",
       " 'location': ['Location', 'location'],\n",
       " 'meters': ['Meters', 'meters'],\n",
       " 'new.recap': ['NEW/recap', 'New/Recap'],\n",
       " 'painted': ['Painted', 'painted or not', ' painted or not', 'painted'],\n",
       " 'misc': ['misc/notes', 'misc', 'Misc.'],\n",
       " 'vial': ['VIAL', 'Vial'],\n",
       " 'year': ['Year', '1st Capture (year)', 'Years Alive (known)'],\n",
       " 'autotomized': ['Tail condition (1=intact; 2=autotomized; 3=regrown)'],\n",
       " 'sighting': [],\n",
       " 'toes': ['Toes', 'TOES']}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(keepCol).apply(lambda x: colmatchtodict(x=x,series=pd.Series(uniquecols),dictsource=coldict))\n",
    "coldict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='AppendingData'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Appending Data\n",
    "[Top](#TOC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ExportingData'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exporting Data\n",
    "[Top](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
