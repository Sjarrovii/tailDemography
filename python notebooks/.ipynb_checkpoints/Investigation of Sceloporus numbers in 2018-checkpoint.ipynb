{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evauation of *Sceloporus jarrovii* and *S. virgatus* population sizes in Crystal Creek\n",
    "## George Middendorf and Christopher Agard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "The intent of this notebook is to determine if the numbers of *Sceloporus jarrovii* and *S. virgatus* captured in Crystal Creek are in fact lower than in previous years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods\n",
    "We will begin by identifying a set of years in the existing cleaned data set during which the search period begins at a point in the year comparable to the start of the 2018 search period (i.e., mid-August). We will then determine the number of lizards captured for each year.  Finally, we will compare the number of lizards captured, looking for significant differences in the overall number of captures and the number of captures according to various demographics (sex, size-range, and previous capture status)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pandas packages will be our workhorse here, but we will need the os package for a few things too.  We'll also increase the maximum number of rows that are displyed on each print in order to make reviewing results easier. We'll be using plotly to creae any figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os,glob,time\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "plotly.tools.set_config_file(world_readable=True)\n",
    "\n",
    "pd.options.display.max_rows = 99999\n",
    "pd.options.display.max_columns = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in necessary data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will designate the paths from which to read data and to which output files should be written."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source Data\n",
    "sourceDataBig = 'S:/Chris/TailDemography/data'\n",
    "\n",
    "#Output Data paths\n",
    "outputBig = 'S:/Chris/TailDemography/data'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need to change the working directory to the right paths and read in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cleaned CC data 2000-2017_2018-09-07 22_47_08.525360.csv',\n",
       " 'cleaned CC data 2000-2017_2018-09-08 16_41_11.234222.csv',\n",
       " 'cleaned CC data 2000-2017_2018-09-08 23_41_22.661706.csv',\n",
       " 'cleaned CC data 2000-2017_2018-09-11 21_19_30.768558.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(sourceDataBig)\n",
    "\n",
    "combinedFiles = glob.glob('cleaned CC data 2000-2017*')\n",
    "combinedFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000-2017 species included:\n",
      "['j' 'uo' 'v' 'sc' 'cn ex']\n"
     ]
    }
   ],
   "source": [
    "dfPrev=pd.read_csv(combinedFiles[-1])\n",
    "print('2000-2017 species included:\\n{}'.format(dfPrev.species.unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018 species included:\n",
      "[nan 'Sj' 'Sv' 'Other (Other)' 'Other' 'Uo' 'A spp']\n"
     ]
    }
   ],
   "source": [
    "df2018=pd.read_csv('CC Data 2018 - Data Entry Sheet.csv')\n",
    "print('2018 species included:\\n{}'.format(df2018.Species.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will only consider *S. jarrovii* and *S. virgatus* for our comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000-2017 species included:\n",
      "['j' 'v']\n",
      "2018 species included:\n",
      "['Sj' 'Sv']\n"
     ]
    }
   ],
   "source": [
    "dfPrev = dfPrev.loc[dfPrev.species.isin(['j','v'])]\n",
    "print('2000-2017 species included:\\n{}'.format(dfPrev.species.unique()))\n",
    "\n",
    "df2018 = df2018.loc[df2018.Species.isin(['Sj','Sv'])]\n",
    "print('2018 species included:\\n{}'.format(df2018.Species.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to coerce the dates in both data sets to datetime objects.  In order to compare across years in a figure we will also have to create a new variable, __week__, which represents that date as the week of the year (*i.e.*, from 1 to 52). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPrev.date = pd.to_datetime(dfPrev.date,errors='coerce')\n",
    "df2018.Date = pd.to_datetime(df2018.Date,errors='coerce')\n",
    "\n",
    "dfPrev['week'] = dfPrev.date.dt.weekofyear\n",
    "df2018['week'] = df2018.Date.dt.weekofyear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can graph the timeperiods over which we captured lizards in both data sets to see which years overlapped with 2018.  We wil use a series of horizontal violin plots for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~cragard/57.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2000 = go.Violin(x=dfPrev.loc[dfPrev.year == 2000,\"week\"],name= '2000')\n",
    "y2001 = go.Violin(x=dfPrev.loc[dfPrev.year == 2001,\"week\"],name= '2001')\n",
    "y2002 = go.Violin(x=dfPrev.loc[dfPrev.year == 2002,\"week\"],name= '2002')\n",
    "y2003 = go.Violin(x=dfPrev.loc[dfPrev.year == 2003,\"week\"],name= '2003')\n",
    "y2004 = go.Violin(x=dfPrev.loc[dfPrev.year == 2004,\"week\"],name= '2004')\n",
    "y2005 = go.Violin(x=dfPrev.loc[dfPrev.year == 2005,\"week\"],name= '2005')\n",
    "y2006 = go.Violin(x=dfPrev.loc[dfPrev.year == 2006,\"week\"],name= '2006')\n",
    "y2007 = go.Violin(x=dfPrev.loc[dfPrev.year == 2007,\"week\"],name= '2007')\n",
    "y2008 = go.Violin(x=dfPrev.loc[dfPrev.year == 2008,\"week\"],name= '2008')\n",
    "y2009 = go.Violin(x=dfPrev.loc[dfPrev.year == 2009,\"week\"],name= '2009')\n",
    "y2010 = go.Violin(x=dfPrev.loc[dfPrev.year == 2010,\"week\"],name= '2010')\n",
    "y2011 = go.Violin(x=dfPrev.loc[dfPrev.year == 2011,\"week\"],name= '2011')\n",
    "y2012 = go.Violin(x=dfPrev.loc[dfPrev.year == 2012,\"week\"],name= '2012')\n",
    "y2013 = go.Violin(x=dfPrev.loc[dfPrev.year == 2013,\"week\"],name= '2013')\n",
    "y2014 = go.Violin(x=dfPrev.loc[dfPrev.year == 2014,\"week\"],name= '2014')\n",
    "y2015 = go.Violin(x=dfPrev.loc[dfPrev.year == 2015,\"week\"],name= '2015')\n",
    "y2016 = go.Violin(x=dfPrev.loc[dfPrev.year == 2016,\"week\"],name= '2016')\n",
    "y2017 = go.Violin(x=dfPrev.loc[dfPrev.year == 2017,\"week\"],name= '2017')\n",
    "y2018 = go.Violin(x=df2018.week,name= '2018')\n",
    "\n",
    "dataPrev = [y2000,y2001,y2002,y2003,y2004,\n",
    "        y2005,y2006,y2007,y2008,y2009,\n",
    "        y2010,y2011,y2012,y2013,y2014,\n",
    "        y2015,y2016,y2017,y2018]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title = 'Distribution of Captures in Crystal Creek by Year',\n",
    "    titlefont = dict(\n",
    "        size = 20),\n",
    "    yaxis = dict(\n",
    "        title = 'Year',\n",
    "        dtick = 1,\n",
    "        titlefont = dict(\n",
    "            size = 18)),\n",
    "    xaxis = dict(\n",
    "        title = 'Week of the Year',\n",
    "        dtick = 1,\n",
    "        titlefont = dict(\n",
    "            size = 18)))\n",
    "\n",
    "fig = go.Figure(\n",
    "    data = dataPrev, \n",
    "    layout = layout)\n",
    "\n",
    "py.iplot(fig, filename = 'Violin plot of Captures in CC by Week in the Year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like there's no year that completely overlaps 2018, but the most overlap in the sample occurs with 2001, 2010, 2002, and 2000, with 2001 overlapping the most.  These will be the years we use to determine if 2018 capture rates we abnormal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's reduce the dfPrev to only include data for 2000-2002 and 2010."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPrev = dfPrev.loc[dfPrev.year.isin([2000,2001,2002,2010])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
