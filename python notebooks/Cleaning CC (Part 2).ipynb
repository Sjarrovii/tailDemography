{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning CC data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This python notebook operates on a csv created after editing in open refine and is designed to finish cleaning columns of interest which were easier to clean in python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Resume Here](#resumehere)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='TOC'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "1. [Setting up Python](#SettingUp)\n",
    "    \n",
    "    1. [Setting the Location](#SettingLoc)\n",
    "    \n",
    "    2. [Importing Data](#ImportingData)\n",
    "    \n",
    "    3. [Preparing for a Save](#PreparingSave)\n",
    "\n",
    "    \n",
    "2. [Inspecting the Data](#InspectingData)\n",
    "3. [Cleaning Data](#CleaningData)\n",
    "\n",
    "    1. [Inspecting the Data](#InspectingData)\n",
    "    \n",
    "    2. [Column by Column Cleaning](#ColbyCol)\n",
    "        1.\n",
    "    \n",
    "    3. [Correcting class of columns](#CorrectingClass)\n",
    "    \n",
    "    4. [Cleaning Toes](#CleaningToes)\n",
    "    \n",
    "4. [Adding Columns](#AddCol)\n",
    "\n",
    "    1. [TL_SVL](#TlSvl)\n",
    "    \n",
    "    2. [Mass_SVL](#MassSvl)\n",
    "    \n",
    "    3. [Lizard Number](#LizardNumber)\n",
    "\n",
    "5. [Export Cleaned Data](#exportFinal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='SettingUp'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up Python\n",
    "\n",
    "[Top](#TOC)\n",
    "\n",
    "Here we import necessary packages. \n",
    "This chunk may take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from liz_number import lizsort,mindate,smallest,validate\n",
    "from liz_toes import make_str,label_pattern, replace_pattern,report_pattern\n",
    "\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "plotly.tools.set_config_file(world_readable=True)\n",
    "\n",
    "# increase print limit\n",
    "pd.options.display.max_rows = 99999\n",
    "pd.options.display.max_columns = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='SettingLoc'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting the location\n",
    "[Top](#TOC)\n",
    "\n",
    "These chunks identify the locations from which we can get data and to which we can save data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Source Data\n",
    "Source files can be found in the following locations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sourceDataPers = 'C:/Users/Christopher/Google Drive/TailDemography/Cleaned Combined Data'\n",
    "sourceDataBig = 'S:/Chris/TailDemography/TailDemography/Cleaned Combined Data'\n",
    "# sourceBlack = 'C:/Users/test/Desktop'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Intermediate Source Data\n",
    "Intermediate files can be found in the following locations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sourceInterDataPers = 'C:/Users/Christopher/Google Drive/TailDemography/Intermediate Files/DeepCleaning'\n",
    "sourceinterDataBig = 'S:/Chris/TailDemography/TailDemography/Intermediate Files/DeepCleaning'\n",
    "# sourceBlack = 'C:/Users/test/Desktop'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output Data paths\n",
    "Outputfiles can be found in the following locations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputPers = 'C:/Users/Christopher/Google Drive/TailDemography/outputFiles'\n",
    "outputBig = 'S:/Chris/TailDemography/TailDemography/outputFiles'\n",
    "# outputBlack = 'C:/Users/test/Desktop'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ImportingData'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data\n",
    "[Top](#TOC)\n",
    "\n",
    "Here we import data from one of the available locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>autotomized</th>\n",
       "      <th>date</th>\n",
       "      <th>location</th>\n",
       "      <th>meters</th>\n",
       "      <th>misc</th>\n",
       "      <th>new.recap</th>\n",
       "      <th>paint.mark</th>\n",
       "      <th>painted</th>\n",
       "      <th>sighting</th>\n",
       "      <th>species</th>\n",
       "      <th>svl</th>\n",
       "      <th>tl</th>\n",
       "      <th>rtl</th>\n",
       "      <th>mass</th>\n",
       "      <th>sex</th>\n",
       "      <th>toes</th>\n",
       "      <th>vial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2001-03-18 00:00:00</td>\n",
       "      <td>r wall at juniper xing</td>\n",
       "      <td>113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NEW</td>\n",
       "      <td>w.c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sj</td>\n",
       "      <td>76</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>13.7</td>\n",
       "      <td>m</td>\n",
       "      <td>2-6-11-16</td>\n",
       "      <td>toes in vial 01-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2001-03-18 00:00:00</td>\n",
       "      <td>r wall at juniper xing</td>\n",
       "      <td>113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NEW</td>\n",
       "      <td>w.b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sj</td>\n",
       "      <td>82</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>f</td>\n",
       "      <td>2-6-11-18</td>\n",
       "      <td>toes in vial 01-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2001-03-18 00:00:00</td>\n",
       "      <td>r wall at juniper xing</td>\n",
       "      <td>113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NEW</td>\n",
       "      <td>w.a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sj</td>\n",
       "      <td>58</td>\n",
       "      <td>69</td>\n",
       "      <td>-1</td>\n",
       "      <td>8.5</td>\n",
       "      <td>f</td>\n",
       "      <td>2-6-11-19</td>\n",
       "      <td>toes in vial 01-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2001-03-18 00:00:00</td>\n",
       "      <td>r wall at juniper xing</td>\n",
       "      <td>113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NEW</td>\n",
       "      <td>w-a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sj</td>\n",
       "      <td>65</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>9.2</td>\n",
       "      <td>m</td>\n",
       "      <td>2-6-11-20</td>\n",
       "      <td>toes in vial 01-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2001-03-18 00:00:00</td>\n",
       "      <td>r wall at juniper xing</td>\n",
       "      <td>113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NEW</td>\n",
       "      <td>w-b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sj</td>\n",
       "      <td>58</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>f</td>\n",
       "      <td>2-6-11-19-20</td>\n",
       "      <td>toes in vial 01-5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   autotomized                 date                location meters misc  \\\n",
       "0          NaN  2001-03-18 00:00:00  r wall at juniper xing    113  NaN   \n",
       "1          NaN  2001-03-18 00:00:00  r wall at juniper xing    113  NaN   \n",
       "2          NaN  2001-03-18 00:00:00  r wall at juniper xing    113  NaN   \n",
       "3          NaN  2001-03-18 00:00:00  r wall at juniper xing    113  NaN   \n",
       "4          NaN  2001-03-18 00:00:00  r wall at juniper xing    113  NaN   \n",
       "\n",
       "  new.recap paint.mark painted  sighting species svl   tl rtl  mass sex  \\\n",
       "0       NEW        w.c     NaN       NaN      sj  76   80   1  13.7   m   \n",
       "1       NEW        w.b     NaN       NaN      sj  82  109   0  17.5   f   \n",
       "2       NEW        w.a     NaN       NaN      sj  58   69  -1   8.5   f   \n",
       "3       NEW        w-a     NaN       NaN      sj  65   91   0   9.2   m   \n",
       "4       NEW        w-b     NaN       NaN      sj  58   76   0   7.8   f   \n",
       "\n",
       "            toes               vial  \n",
       "0      2-6-11-16  toes in vial 01-1  \n",
       "1      2-6-11-18  toes in vial 01-2  \n",
       "2      2-6-11-19  toes in vial 01-3  \n",
       "3      2-6-11-20  toes in vial 01-4  \n",
       "4   2-6-11-19-20  toes in vial 01-5  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(sourceDataBig)\n",
    "df=pd.read_csv('Appended and Trimmed CC Data 2000-2017_2018-12-26 21hrs26min.csv')\n",
    "df = df.reindex(['date', 'location', 'meters', 'new.recap', 'painted', 'sighting',\n",
    "       'species', 'svl', 'tl',  'rtl', 'mass', 'sex','autotomized', 'paint.mark',\n",
    "                 'toes', 'vial','misc',], axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='PreparingSave'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing for a save\n",
    "[Top](#TOC)\n",
    "\n",
    "Now we change the working directory so that inermediate files are saved to our preferred location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>autotomized</th>\n",
       "      <th>date</th>\n",
       "      <th>location</th>\n",
       "      <th>meters</th>\n",
       "      <th>misc</th>\n",
       "      <th>new.recap</th>\n",
       "      <th>paint.mark</th>\n",
       "      <th>painted</th>\n",
       "      <th>sighting</th>\n",
       "      <th>species</th>\n",
       "      <th>svl</th>\n",
       "      <th>tl</th>\n",
       "      <th>rtl</th>\n",
       "      <th>mass</th>\n",
       "      <th>sex</th>\n",
       "      <th>toes</th>\n",
       "      <th>vial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2001-03-18 00:00:00</td>\n",
       "      <td>r wall at juniper xing</td>\n",
       "      <td>113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NEW</td>\n",
       "      <td>w.c</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sj</td>\n",
       "      <td>76</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>13.7</td>\n",
       "      <td>m</td>\n",
       "      <td>2-6-11-16</td>\n",
       "      <td>toes in vial 01-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2001-03-18 00:00:00</td>\n",
       "      <td>r wall at juniper xing</td>\n",
       "      <td>113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NEW</td>\n",
       "      <td>w.b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sj</td>\n",
       "      <td>82</td>\n",
       "      <td>109</td>\n",
       "      <td>0</td>\n",
       "      <td>17.5</td>\n",
       "      <td>f</td>\n",
       "      <td>2-6-11-18</td>\n",
       "      <td>toes in vial 01-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2001-03-18 00:00:00</td>\n",
       "      <td>r wall at juniper xing</td>\n",
       "      <td>113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NEW</td>\n",
       "      <td>w.a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sj</td>\n",
       "      <td>58</td>\n",
       "      <td>69</td>\n",
       "      <td>-1</td>\n",
       "      <td>8.5</td>\n",
       "      <td>f</td>\n",
       "      <td>2-6-11-19</td>\n",
       "      <td>toes in vial 01-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2001-03-18 00:00:00</td>\n",
       "      <td>r wall at juniper xing</td>\n",
       "      <td>113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NEW</td>\n",
       "      <td>w-a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sj</td>\n",
       "      <td>65</td>\n",
       "      <td>91</td>\n",
       "      <td>0</td>\n",
       "      <td>9.2</td>\n",
       "      <td>m</td>\n",
       "      <td>2-6-11-20</td>\n",
       "      <td>toes in vial 01-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2001-03-18 00:00:00</td>\n",
       "      <td>r wall at juniper xing</td>\n",
       "      <td>113</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NEW</td>\n",
       "      <td>w-b</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sj</td>\n",
       "      <td>58</td>\n",
       "      <td>76</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8</td>\n",
       "      <td>f</td>\n",
       "      <td>2-6-11-19-20</td>\n",
       "      <td>toes in vial 01-5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   autotomized                 date                location meters misc  \\\n",
       "0          NaN  2001-03-18 00:00:00  r wall at juniper xing    113  NaN   \n",
       "1          NaN  2001-03-18 00:00:00  r wall at juniper xing    113  NaN   \n",
       "2          NaN  2001-03-18 00:00:00  r wall at juniper xing    113  NaN   \n",
       "3          NaN  2001-03-18 00:00:00  r wall at juniper xing    113  NaN   \n",
       "4          NaN  2001-03-18 00:00:00  r wall at juniper xing    113  NaN   \n",
       "\n",
       "  new.recap paint.mark painted  sighting species svl   tl rtl  mass sex  \\\n",
       "0       NEW        w.c     NaN       NaN      sj  76   80   1  13.7   m   \n",
       "1       NEW        w.b     NaN       NaN      sj  82  109   0  17.5   f   \n",
       "2       NEW        w.a     NaN       NaN      sj  58   69  -1   8.5   f   \n",
       "3       NEW        w-a     NaN       NaN      sj  65   91   0   9.2   m   \n",
       "4       NEW        w-b     NaN       NaN      sj  58   76   0   7.8   f   \n",
       "\n",
       "            toes               vial  \n",
       "0      2-6-11-16  toes in vial 01-1  \n",
       "1      2-6-11-18  toes in vial 01-2  \n",
       "2      2-6-11-19  toes in vial 01-3  \n",
       "3      2-6-11-20  toes in vial 01-4  \n",
       "4   2-6-11-19-20  toes in vial 01-5  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(sourceDataBig)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id= 'InspectingData'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id= 'CleaningData'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning the Data\n",
    "[Top](#TOC)\n",
    "\n",
    "Now we get to the actual cleaning of the data.  We will inspect the data and take the appropriate cleaning steps:\n",
    "- [Inspecting the Data](#InspectingData)\n",
    "- [Column-by-Column Cleaning](#ColByCol)\n",
    "    - [autotomized](#autotomized)\n",
    "- [Correcting class of columns](#CorrectingClass)\n",
    "- [Cleaning Toes](#CleaningToes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting the Data\n",
    "[Top](#TOC)\n",
    "\n",
    "[Top Cleaning](#CleaningData)\n",
    "\n",
    "Let's take a look at the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "There are 6597 data points in our data set.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nThere are {} data points in our data set.\".format(df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The columns in the data have the following data types:\n",
      "autotomized    float64\n",
      "date            object\n",
      "location        object\n",
      "meters          object\n",
      "misc            object\n",
      "new.recap       object\n",
      "paint.mark      object\n",
      "painted         object\n",
      "sighting       float64\n",
      "species         object\n",
      "svl             object\n",
      "tl              object\n",
      "rtl             object\n",
      "mass            object\n",
      "sex             object\n",
      "toes            object\n",
      "vial            object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nThe columns in the data have the following data types:\\n{}\".format(df.dtypes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='ColbyCol'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Column-by-Column Cleaning\n",
    "[Back to: Top](#TOC)\n",
    "\n",
    "We will handle the cleaning for each column in this section.\n",
    "\n",
    "1. [rtl](#rtl)\n",
    "2. [autotomized](#autotomized)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='rtl'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 'rtl' \n",
    "[Back to: Top](#TOC)\n",
    "\n",
    "[Back to: Cleaning](#CleaningData)\n",
    "\n",
    "[Back to: Column-by-Column Cleaning](#ColByCol)\n",
    "\n",
    "Here we investigate and clean values in the column 'rtl'. These should be int type values that are greater than or equal to -1.  First, we test to see if all of the values are of type int."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'badtypes' represents 3937 entries in the df:\n",
      "\n",
      "All values in df.rtl could not be converted to int.  The following values could not be converted and should be investigated:\n",
      "\n",
      "[nan, '32 -12', 'o', '?', '-', '10(kink)']\n",
      "\n",
      "badtypes values are distributed as follows in the df:\n",
      "\n",
      "NaN         3931\n",
      "?              2\n",
      "o              1\n",
      "-              1\n",
      "10(kink)       1\n",
      "32 -12         1\n",
      "Name: rtl, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "badtypes = []\n",
    "for val in df.rtl:\n",
    "    try:\n",
    "        x = isinstance(type(int(val)),int)\n",
    "    except:\n",
    "        badtypes=badtypes+[val]\n",
    "print(\"'badtypes' represents {} entries in the df:\".format(len(badtypes)))\n",
    "if len(badtypes)==0:\n",
    "    print(\"\\nAll values in df.rtl can be successfuly converted to int.\\n\\n\")\n",
    "#     df['rtl'] = df.rtl.apply(int)\n",
    "else:\n",
    "    print(\"\\nAll values in df.rtl could not be converted to int.  The following values could not be \\\n",
    "converted and should be investigated:\\n\\n{}\\n\\nbadtypes values are distributed as follows in the df:\\n\\n{}\"\\\n",
    "          .format(list(set(badtypes)),df.loc[df.rtl.isin(badtypes),'rtl'].value_counts(dropna=False)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The non-NaN values are few, so we will inspect these first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>autotomized</th>\n",
       "      <th>date</th>\n",
       "      <th>location</th>\n",
       "      <th>meters</th>\n",
       "      <th>misc</th>\n",
       "      <th>new.recap</th>\n",
       "      <th>paint.mark</th>\n",
       "      <th>painted</th>\n",
       "      <th>sighting</th>\n",
       "      <th>species</th>\n",
       "      <th>svl</th>\n",
       "      <th>tl</th>\n",
       "      <th>rtl</th>\n",
       "      <th>mass</th>\n",
       "      <th>sex</th>\n",
       "      <th>toes</th>\n",
       "      <th>vial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2244</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2003-04-19 00:00:00</td>\n",
       "      <td>talus 326</td>\n",
       "      <td>326</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NEW</td>\n",
       "      <td>b7c</td>\n",
       "      <td>painted</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sj</td>\n",
       "      <td>56</td>\n",
       "      <td>32</td>\n",
       "      <td>?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2267</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2003-04-30 00:00:00</td>\n",
       "      <td>wall 15m</td>\n",
       "      <td>15</td>\n",
       "      <td>9 looks like a backwards P and t combined</td>\n",
       "      <td>recap</td>\n",
       "      <td>b9a</td>\n",
       "      <td>painted</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sj</td>\n",
       "      <td>76</td>\n",
       "      <td>19</td>\n",
       "      <td>?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>4-10-14-18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2397</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2003-06-27 00:00:00</td>\n",
       "      <td>sb 5m ^ cave trail</td>\n",
       "      <td>50</td>\n",
       "      <td>lost toes for vial, accidently cut off toe 11</td>\n",
       "      <td>NEW</td>\n",
       "      <td>sMb</td>\n",
       "      <td>painted</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sv</td>\n",
       "      <td>41</td>\n",
       "      <td>60</td>\n",
       "      <td>o</td>\n",
       "      <td>4</td>\n",
       "      <td>m</td>\n",
       "      <td>1-6-11-20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3452</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2004-07-12 00:00:00</td>\n",
       "      <td>sb opp fallen juniper -&gt; flat R</td>\n",
       "      <td>208</td>\n",
       "      <td>blue throat and blue belly; accidentally cut t...</td>\n",
       "      <td>new</td>\n",
       "      <td>w^c</td>\n",
       "      <td>painted</td>\n",
       "      <td>NaN</td>\n",
       "      <td>uo</td>\n",
       "      <td>52</td>\n",
       "      <td>75</td>\n",
       "      <td>32 -12</td>\n",
       "      <td>4.7</td>\n",
       "      <td>m</td>\n",
       "      <td>4-6-18</td>\n",
       "      <td>04-63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3548</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2004-07-21 00:00:00</td>\n",
       "      <td>sb @ cc/ccc</td>\n",
       "      <td>240</td>\n",
       "      <td>escaped</td>\n",
       "      <td>recap</td>\n",
       "      <td>w148b</td>\n",
       "      <td>painted</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sv</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>6</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3575</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2004-07-22 00:00:00</td>\n",
       "      <td>wall rt side v wall v cave tr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hurt toes 11-13 in capture; Bss Tss</td>\n",
       "      <td>recap</td>\n",
       "      <td>w154b</td>\n",
       "      <td>painted</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sj</td>\n",
       "      <td>65</td>\n",
       "      <td>94</td>\n",
       "      <td>10(kink)</td>\n",
       "      <td>9.4</td>\n",
       "      <td>f</td>\n",
       "      <td>2-9-12-18</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      autotomized                 date                         location  \\\n",
       "2244          NaN  2003-04-19 00:00:00                        talus 326   \n",
       "2267          NaN  2003-04-30 00:00:00                         wall 15m   \n",
       "2397          NaN  2003-06-27 00:00:00               sb 5m ^ cave trail   \n",
       "3452          NaN  2004-07-12 00:00:00  sb opp fallen juniper -> flat R   \n",
       "3548          NaN  2004-07-21 00:00:00                      sb @ cc/ccc   \n",
       "3575          NaN  2004-07-22 00:00:00    wall rt side v wall v cave tr   \n",
       "\n",
       "     meters                                               misc new.recap  \\\n",
       "2244    326                                                NaN       NEW   \n",
       "2267     15          9 looks like a backwards P and t combined     recap   \n",
       "2397     50      lost toes for vial, accidently cut off toe 11       NEW   \n",
       "3452    208  blue throat and blue belly; accidentally cut t...       new   \n",
       "3548    240                                            escaped     recap   \n",
       "3575    NaN                hurt toes 11-13 in capture; Bss Tss     recap   \n",
       "\n",
       "     paint.mark  painted  sighting species svl  tl       rtl mass sex  \\\n",
       "2244        b7c  painted       NaN      sj  56  32         ?  NaN   m   \n",
       "2267        b9a  painted       NaN      sj  76  19         ?  NaN   m   \n",
       "2397        sMb  painted       NaN      sv  41  60         o    4   m   \n",
       "3452        w^c  painted       NaN      uo  52  75    32 -12  4.7   m   \n",
       "3548      w148b  painted       NaN      sv   -   -         -    6   f   \n",
       "3575      w154b  painted       NaN      sj  65  94  10(kink)  9.4   f   \n",
       "\n",
       "             toes    vial  \n",
       "2244          NaN     NaN  \n",
       "2267   4-10-14-18     NaN  \n",
       "2397    1-6-11-20     NaN  \n",
       "3452       4-6-18   04-63  \n",
       "3548          NaN     NaN  \n",
       "3575    2-9-12-18     NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[(df.rtl.isin(badtypes))&(df.rtl.notna()),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We can try to further classify the NaN values in the rtl column. Those with no other measurements (svl, tl, or mass) will be of little use to us and can probably safely be ignored as they willlikely be droppd from any further analysis.  Let's see how many of these there are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3924"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx_nomeasurement = ((df.rtl.isna())&(df.svl.isna())&(df.tl.isna()))\n",
    "df.loc[idx_nomeasurement].shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Almost all of the entries of concern are accounted for here.  We will drop these from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping the entries with no measurements at all, the df now has 2673 entries.\n"
     ]
    }
   ],
   "source": [
    "df = df.loc[~idx_nomeasurement]\n",
    "print(\"After dropping the entries with no measurements at all, the df now has {} entries.\"\\\n",
    "      .format(df.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will inspect those that had at least one other length measurement (svl or tl)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>autotomized</th>\n",
       "      <th>date</th>\n",
       "      <th>location</th>\n",
       "      <th>meters</th>\n",
       "      <th>misc</th>\n",
       "      <th>new.recap</th>\n",
       "      <th>paint.mark</th>\n",
       "      <th>painted</th>\n",
       "      <th>sighting</th>\n",
       "      <th>species</th>\n",
       "      <th>svl</th>\n",
       "      <th>tl</th>\n",
       "      <th>rtl</th>\n",
       "      <th>mass</th>\n",
       "      <th>sex</th>\n",
       "      <th>toes</th>\n",
       "      <th>vial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2001-03-23 00:00:00</td>\n",
       "      <td>bottom R wall v cave trail</td>\n",
       "      <td>30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sighting</td>\n",
       "      <td>?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sj</td>\n",
       "      <td>~70</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>2-6-13-20</td>\n",
       "      <td>could read toes 6,13 for certain; toe 2 uncert...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2002-03-16 00:00:00</td>\n",
       "      <td>active in crevice in wall 3m v juniper xing</td>\n",
       "      <td>112</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sighting</td>\n",
       "      <td>?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sj</td>\n",
       "      <td>large</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2002-03-17 00:00:00</td>\n",
       "      <td>H4a</td>\n",
       "      <td>194</td>\n",
       "      <td>probably w85a but could only see the \"5\"</td>\n",
       "      <td>sighting</td>\n",
       "      <td>w85a??</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sj</td>\n",
       "      <td>large</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1513</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2002-03-20 00:00:00</td>\n",
       "      <td>L across from wall</td>\n",
       "      <td>318</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sighting</td>\n",
       "      <td>w||t</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sj</td>\n",
       "      <td>large</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>f</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1978</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2002-03-19 00:00:00</td>\n",
       "      <td>up rt wall @ pool</td>\n",
       "      <td>NaN</td>\n",
       "      <td>~25mm original T; rest regrown</td>\n",
       "      <td>sighting</td>\n",
       "      <td>???</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sj</td>\n",
       "      <td>large</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>m</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2122</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2002-03-19 00:00:00</td>\n",
       "      <td>sb 4m ^ flatR</td>\n",
       "      <td>NaN</td>\n",
       "      <td>had moth so didn'tcatch</td>\n",
       "      <td>sighting</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sv</td>\n",
       "      <td>small</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>?</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2004-07-04 00:00:00</td>\n",
       "      <td>bottom chute</td>\n",
       "      <td>355</td>\n",
       "      <td>few mites</td>\n",
       "      <td>recap</td>\n",
       "      <td>w.t</td>\n",
       "      <td>painted</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sv</td>\n",
       "      <td>52</td>\n",
       "      <td>53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.6</td>\n",
       "      <td>m</td>\n",
       "      <td>1-6-16-17-20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      autotomized                 date  \\\n",
       "148           NaN  2001-03-23 00:00:00   \n",
       "980           NaN  2002-03-16 00:00:00   \n",
       "1152          NaN  2002-03-17 00:00:00   \n",
       "1513          NaN  2002-03-20 00:00:00   \n",
       "1978          NaN  2002-03-19 00:00:00   \n",
       "2122          NaN  2002-03-19 00:00:00   \n",
       "3262          NaN  2004-07-04 00:00:00   \n",
       "\n",
       "                                         location meters  \\\n",
       "148                    bottom R wall v cave trail     30   \n",
       "980   active in crevice in wall 3m v juniper xing    112   \n",
       "1152                                          H4a    194   \n",
       "1513                           L across from wall    318   \n",
       "1978                            up rt wall @ pool    NaN   \n",
       "2122                                sb 4m ^ flatR    NaN   \n",
       "3262                                 bottom chute    355   \n",
       "\n",
       "                                          misc new.recap paint.mark  painted  \\\n",
       "148                                        NaN  sighting          ?      NaN   \n",
       "980                                        NaN  sighting          ?      NaN   \n",
       "1152  probably w85a but could only see the \"5\"  sighting     w85a??      NaN   \n",
       "1513                                       NaN  sighting       w||t      NaN   \n",
       "1978            ~25mm original T; rest regrown  sighting        ???      NaN   \n",
       "2122                   had moth so didn'tcatch  sighting        NaN      NaN   \n",
       "3262                                 few mites     recap        w.t  painted   \n",
       "\n",
       "      sighting species    svl   tl  rtl mass  sex          toes  \\\n",
       "148        NaN      sj    ~70  NaN  NaN  NaN    f     2-6-13-20   \n",
       "980        NaN      sj  large  NaN  NaN  NaN    m           NaN   \n",
       "1152       NaN      sj  large  NaN  NaN  NaN  NaN           NaN   \n",
       "1513       NaN      sj  large  NaN  NaN  NaN    f           NaN   \n",
       "1978       NaN      sj  large  NaN  NaN  NaN    m           NaN   \n",
       "2122       NaN      sv  small  NaN  NaN  NaN    ?           NaN   \n",
       "3262       NaN      sv     52   53  NaN  3.6    m  1-6-16-17-20   \n",
       "\n",
       "                                                   vial  \n",
       "148   could read toes 6,13 for certain; toe 2 uncert...  \n",
       "980                                                 NaN  \n",
       "1152                                                NaN  \n",
       "1513                                                NaN  \n",
       "1978                                                NaN  \n",
       "2122                                                NaN  \n",
       "3262                                                NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[(df.rtl.isna())&((df.svl.notna())|(df.tl.notna())),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All but one of these was a sighting.  We will have to look at the field notes to confirm whether or not data were actually missing for the remaining entry.  We will also have to decide if we will drop the sightings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>autotomized</th>\n",
       "      <th>date</th>\n",
       "      <th>location</th>\n",
       "      <th>meters</th>\n",
       "      <th>misc</th>\n",
       "      <th>new.recap</th>\n",
       "      <th>paint.mark</th>\n",
       "      <th>painted</th>\n",
       "      <th>sighting</th>\n",
       "      <th>species</th>\n",
       "      <th>svl</th>\n",
       "      <th>tl</th>\n",
       "      <th>rtl</th>\n",
       "      <th>mass</th>\n",
       "      <th>sex</th>\n",
       "      <th>toes</th>\n",
       "      <th>vial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3262</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2004-07-04 00:00:00</td>\n",
       "      <td>bottom chute</td>\n",
       "      <td>355</td>\n",
       "      <td>few mites</td>\n",
       "      <td>recap</td>\n",
       "      <td>w.t</td>\n",
       "      <td>painted</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sv</td>\n",
       "      <td>52</td>\n",
       "      <td>53</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.6</td>\n",
       "      <td>m</td>\n",
       "      <td>1-6-16-17-20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      autotomized                 date      location meters       misc  \\\n",
       "3262          NaN  2004-07-04 00:00:00  bottom chute    355  few mites   \n",
       "\n",
       "     new.recap paint.mark  painted  sighting species svl  tl  rtl mass sex  \\\n",
       "3262     recap        w.t  painted       NaN      sv  52  53  NaN  3.6   m   \n",
       "\n",
       "              toes vial  \n",
       "3262  1-6-16-17-20  NaN  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[(df.rtl.isna())&((df.svl.notna())|(df.tl.notna()))&df['new.recap'].str.contains('recap'),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have addressed these, we will force rtl to an int type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we check to see for out of range rtl values, *i.e.* rtl values less than -1 or suspiciously high."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will exclude 0 and -1 values for rtl in these figures because of the large proportion of in range values they account for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<iframe id=\"igraph\" scrolling=\"no\" style=\"border:none;\" seamless=\"seamless\" src=\"https://plot.ly/~cragard/91.embed\" height=\"525px\" width=\"100%\"></iframe>"
      ],
      "text/plain": [
       "<plotly.tools.PlotlyDisplay object>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jarrovii = go.Histogram(x = df.loc[(df.species.str.contains('v|j'))&(~df.rtl.isin(badtypes))\\\n",
    "                                   &(~df.rtl.isin(['0','-1']))\n",
    "                                   ,'rtl'].astype(int, 'ignore'),name = 'S. jarrovii',xbins =dict(size=1)\n",
    "                        ,histnorm='probability', cumulative=dict(enabled = True, direction = 'increasing'))\n",
    "virgatus = go.Histogram(x = df.loc[(df.species.str.contains('v|j'))&(~df.rtl.isin(badtypes))\\\n",
    "                                   &(~df.rtl.isin(['0','-1']))\n",
    "                                   ,'rtl'].astype(int, 'ignore'), name = 'S. virgatus',xbins =dict(size=1)\n",
    "                       ,histnorm='probability', cumulative=dict(enabled = True, direction = 'increasing'))\n",
    "other = go.Histogram(x = df.loc[~(df.species.str.contains('v|j'))&(df.species.notna())\\\n",
    "                                &(~df.rtl.isin(badtypes))&(~df.rtl.isin(['0','-1'])),'rtl']\\\n",
    "                                  .astype(int, 'ignore'), name = 'other',xbins =dict(size=1)\n",
    "                                  ,histnorm='probability', cumulative=dict(enabled = True\n",
    "                                                                           , direction = 'increasing'))\n",
    "data = [jarrovii, virgatus,other]\n",
    "layout = go.Layout(\n",
    "    title = 'Histogram of rtl by species',\n",
    "    titlefont = dict(\n",
    "        size = 20),\n",
    "    xaxis = dict(\n",
    "        dtick = 1,\n",
    "        title = 'rtl (mm)',\n",
    "        titlefont = dict(\n",
    "            size = 18)),\n",
    "    yaxis = dict(\n",
    "        title = 'Number of Lizards',\n",
    "        titlefont = dict(\n",
    "            size = 18))\n",
    ")\n",
    "fig = go.Figure(\n",
    "        data = data,\n",
    "        layout = layout)\n",
    "py.iplot(fig, filename = 'Histogram of rtl by species (new)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps it's worth inspecting values greater than 58. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>autotomized</th>\n",
       "      <th>date</th>\n",
       "      <th>location</th>\n",
       "      <th>meters</th>\n",
       "      <th>misc</th>\n",
       "      <th>new.recap</th>\n",
       "      <th>paint.mark</th>\n",
       "      <th>painted</th>\n",
       "      <th>sighting</th>\n",
       "      <th>species</th>\n",
       "      <th>svl</th>\n",
       "      <th>tl</th>\n",
       "      <th>rtl</th>\n",
       "      <th>mass</th>\n",
       "      <th>sex</th>\n",
       "      <th>toes</th>\n",
       "      <th>vial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2001-07-13 00:00:00</td>\n",
       "      <td>Rs 3m v cave trail</td>\n",
       "      <td>42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>recap</td>\n",
       "      <td>r32a</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sj</td>\n",
       "      <td>93</td>\n",
       "      <td>82</td>\n",
       "      <td>58</td>\n",
       "      <td>24.8</td>\n",
       "      <td>m</td>\n",
       "      <td>5-10-15-16</td>\n",
       "      <td>shed since</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3977</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-05-10 00:00:00</td>\n",
       "      <td>R in sb</td>\n",
       "      <td>-20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>recap</td>\n",
       "      <td>y42c</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>j</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>14.7</td>\n",
       "      <td>m</td>\n",
       "      <td>5-7-13-16</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6297</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-06-20 00:00:00</td>\n",
       "      <td>3m right side ^ Juniper Xing</td>\n",
       "      <td>118</td>\n",
       "      <td>Break at 50, tail still attached w48c -&gt; g18b ...</td>\n",
       "      <td>recap</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sj</td>\n",
       "      <td>7.5</td>\n",
       "      <td>70</td>\n",
       "      <td>90</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>b 1 - 7 - 11</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6303</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2011-06-20 00:00:00</td>\n",
       "      <td>10m up CCC on slab</td>\n",
       "      <td>250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>recap</td>\n",
       "      <td>g19b</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sj</td>\n",
       "      <td>7.6</td>\n",
       "      <td>68</td>\n",
       "      <td>86</td>\n",
       "      <td>0</td>\n",
       "      <td>F</td>\n",
       "      <td>b 2 - 9 - 15 - 17</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6312</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-05-27 00:00:00</td>\n",
       "      <td>sb at CCC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>new</td>\n",
       "      <td>w.a</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cn ex</td>\n",
       "      <td>89</td>\n",
       "      <td>165</td>\n",
       "      <td>75</td>\n",
       "      <td>19</td>\n",
       "      <td>f</td>\n",
       "      <td>1-7</td>\n",
       "      <td>12-27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6375</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2012-05-28 00:00:00</td>\n",
       "      <td>1falls</td>\n",
       "      <td>NaN</td>\n",
       "      <td>salmon tail; Tss</td>\n",
       "      <td>recap</td>\n",
       "      <td>w34c</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sj</td>\n",
       "      <td>79</td>\n",
       "      <td>85</td>\n",
       "      <td>58</td>\n",
       "      <td>19.3</td>\n",
       "      <td>f</td>\n",
       "      <td>3-9-15</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      autotomized                 date                      location meters  \\\n",
       "251           NaN  2001-07-13 00:00:00            Rs 3m v cave trail     42   \n",
       "3977          NaN  2016-05-10 00:00:00                       R in sb    -20   \n",
       "6297          NaN  2011-06-20 00:00:00  3m right side ^ Juniper Xing    118   \n",
       "6303          NaN  2011-06-20 00:00:00            10m up CCC on slab    250   \n",
       "6312          NaN  2012-05-27 00:00:00                     sb at CCC    NaN   \n",
       "6375          NaN  2012-05-28 00:00:00                        1falls    NaN   \n",
       "\n",
       "                                                   misc new.recap paint.mark  \\\n",
       "251                                                 NaN     recap       r32a   \n",
       "3977                                                NaN     recap       y42c   \n",
       "6297  Break at 50, tail still attached w48c -> g18b ...     recap        NaN   \n",
       "6303                                                NaN     recap       g19b   \n",
       "6312                                                NaN       new        w.a   \n",
       "6375                                   salmon tail; Tss     recap       w34c   \n",
       "\n",
       "     painted  sighting species  svl   tl rtl  mass sex               toes  \\\n",
       "251      NaN       NaN      sj   93   82  58  24.8   m         5-10-15-16   \n",
       "3977     yes       NaN       j   80   80  60  14.7   m          5-7-13-16   \n",
       "6297     yes       NaN      sj  7.5   70  90     0   F       b 1 - 7 - 11   \n",
       "6303     yes       NaN      sj  7.6   68  86     0   F  b 2 - 9 - 15 - 17   \n",
       "6312     yes       NaN   cn ex   89  165  75    19   f                1-7   \n",
       "6375     yes       NaN      sj   79   85  58  19.3   f             3-9-15   \n",
       "\n",
       "            vial  \n",
       "251   shed since  \n",
       "3977         NaN  \n",
       "6297         NaN  \n",
       "6303         NaN  \n",
       "6312       12-27  \n",
       "6375         NaN  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[(~df.rtl.isin(badtypes))&(df.loc[(~df.rtl.isin(badtypes)),'rtl'].astype(int, 'ignore')>=58),:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of these values are reasonable, but there are few for which we will need to go back to the field notes in 2011."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id = 'resumehere'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='autotomized'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 'autotomized' \n",
    "[Back to: Top](#TOC)\n",
    "\n",
    "[Back to: Cleaning](#CleaningData)\n",
    "\n",
    "[Back to: Column-by-Column Cleaning](#ColByCol)\n",
    "\n",
    "Here we populate the 'autotomized' column based on the values in 'rtl'.  Most of the source files did not have this category and have NaN values others have float values of 1.0, 2.0 or 3.0 for intact, autotomized with no regrowth or autotomized with regrowth, respectively.  The cleaned data for autotomized will contain  bool type values True, for having experienced auttomy (irrespective fo regrowth) and False for having no evidence of havign experienced autotomy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.autotomized.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will inspect the rtl values for entries with non NaN values for autotomized to determine if we can depend on rtl values to determine autotomy status.  In order to rely on rtl values, the following conditions must be met:\n",
    "- all entries in which autotomized equals 1.0 must have 0 for rtl\n",
    "- all entries in which autotomized equals 2.0 or 3.0 must have -1 or some value >0 for rtl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "intact = df.loc[(df.autotomized==1),'rtl'].astype(int).value_counts(dropna=False)\n",
    "values2check = [x for x in intact.index[intact.index!=0]]\n",
    "if len(values2check)>0:\n",
    "    print(\"The values associated with {} need a closer look.\".format(values2check))\n",
    "else:\n",
    "    print(\"Values for 'intact' entries are as expected.  Continue.\")\n",
    "pd.set_option('max_colwidth',1000)\n",
    "df.loc[(df.autotomized==1)&(df.rtl.astype(int).isin(values2check)),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This lizard appears to have been misrecorded and should be listed as autotomized given the amount of regrowth.  If we depend on the rtl values to label autotomized this will be corrected, so for now we will leave this as is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autotomized = df.loc[(df.autotomized==2),'rtl'].value_counts(dropna=False)\n",
    "values2check = [x for x in autotomized.index[autotomized.index!=-1]]\n",
    "if len(values2check)>0:\n",
    "    print(\"{} values associated with {} need a closer look.\"\\\n",
    "          .format(df.loc[(df.autotomized==2)&(df.rtl.isin(values2check)),:].shape[0],values2check))\n",
    "else:\n",
    "    print(\"Values for 'autotomized' entries are as expected.  Continue.\")\n",
    "pd.set_option('max_colwidth',1000)\n",
    "df.loc[(df.autotomized==2)&(df.rtl.isin(values2check)),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some of these cases are very straight forward given that the ratio of svl to tl is very close to 1, but others would be worth checking the original data to confirm. Another option is to use the svl to tl ratio of animals that we are sure are intact to decide how to classify these."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regrown = df.loc[(df.autotomized==3),'rtl'].value_counts(dropna=False)\n",
    "values2check = [x for x in regrown.index[regrown.index<=0]]\n",
    "if len(values2check)>0:\n",
    "    print(\"The values associated with {} need a closer look.\".format(values2check))\n",
    "else:\n",
    "    print(\"Values for 'regrown' entries are as expected.  Continue.\")\n",
    "pd.set_option('max_colwidth',1000)\n",
    "df.loc[(df.autotomized==3)&(df.rtl.isin(values2check)),:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The entries labeled as a 3.0 in the autotomized column do not appear as though their rtl values will present an issue for calculating new autotomized values.  We will leave these as they are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.loc[((df.autotomized==2)|(df.autotomized==3)),'rtl'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='CorrectingClass'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correcting class of columns\n",
    "[Top](#TOC)\n",
    "\n",
    "[Top Cleaning](#CleaningData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need to add real error handling into these conversion chunks\n",
    "\n",
    "##Convert integer columns to int\n",
    "intCols = ['meters']\n",
    "df[intCols]=df[intCols].astype(int,errors='ignore')\n",
    "\n",
    "##Convert numeric columns to numeric\n",
    "numCols = ['svl','tl','rtl','mass']\n",
    "df[numCols]=df[numCols].apply(pd.to_numeric,errors='coerce')\n",
    "\n",
    "##Convert string columns to str\n",
    "strCols = ['toes','sex','species','vial']\n",
    "df[strCols]=df[strCols].astype(str, errors='ignore')\n",
    "\n",
    "#Convert date to datetime\n",
    "df.loc[df.date==\"NA\"]=np.nan\n",
    "df.date = pd.to_datetime(df.date,errors='coerce')\n",
    "\n",
    "##Convert bool columns to bool\n",
    "# boolCols = ['review_sex','review_species','review_painted','review_new.recap',\\\n",
    "#             'review_rtl','forceMale','forceFemale','forceRecap','forceNew',\\\n",
    "#             'forceSighting','drop_species','drop_morphometrics','autotomized']\n",
    "# df[boolCols]=df[boolCols].astype(bool, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"\\nAfter applying the above changes, the data types are as follows:\\n{}\".format(df.dtypes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='AddVar1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding variables [*year*](#year) and [*rtl_orig*](#rtlorig)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='year'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Year\n",
    "[Back to: Top](#TOC)\n",
    "\n",
    "[Back to: Adding variables](#AddVar1)\n",
    "\n",
    "We will use data contained in the *date* column to create the variable *year*.  TO do this we will define a small function, *myint*, to convert year to an int type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='myint'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myint(x, verbose = False):\n",
    "    try:\n",
    "        x = str(x).split('.')[0]\n",
    "    except:\n",
    "        x = x\n",
    "        if verbose == True:\n",
    "            print('{} is of type {} and cannot be forced to int.'.format(x,type(x)))\n",
    "    return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is are a few examples of how [*myint*](#myint) works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar = [None, 1.0, \"f\"]\n",
    "print([type(x) for x in bar])\n",
    "[myint(x) for x in bar]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bar = [None, 2001.0, \"2001.0\"]\n",
    "print([type(x) for x in bar])\n",
    "[myint(x,True) for x in bar]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we apply [*myint*](#myint) to the 'date' column to create the variable year and inspect the unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year'] = df.date.dt.year.apply(myint,verbose=False)\n",
    "df.year.value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect the entries with 'nan' values.  Note these 'nan' values are string values and not NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.year=='nan',:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='CleaningToes'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning toes column\n",
    "[Top](#TOC)\n",
    "\n",
    "[Top Cleaning](#CleaningData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will rename \"toes\" to \"toes_orig\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns = {'toes':'toes_orig'},index = str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create a new column, \"toes\"  for the renamed toes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['toes'] = df.toes_orig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we attempt to identify problem toes name and correct or export for review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pattern1 = \".( {1,}-.|.- {1,}.)\" # toes entries with any number of spaces on either side of a hyphen\n",
    "pattern2 = \".( {,}\\w{,} {1,}).\" # toes entries with space around or between numbers <- the spaces here should be deleted\n",
    "pattern3 = \".(').\"\n",
    "pattern4 = \"./.\"  # entries with '/' <-- need to replace these with '-'\n",
    "pattern5 = \"(\\?{1,})\"#<-- these needs to be investigated\n",
    "pattern6 = \"^\\d{3,}$\" # entries consist of only a single number comprised of at least three digits \n",
    "#<-- these needs to be investigated by checking raw field notes\n",
    "pattern7 = \".(-{2,}).\" # entries which have at least 2 consecutive '-' <- these should be investigated\n",
    "pattern8 = \"^0\" # entries in which single digit numbers have a leading \"0\" <-- Check raw field notes on this too\n",
    "pattern9 = \"a\\w\" #<--handled hyphens should be inserted  between the [ab] and \\w \n",
    "# entries that contain an 'a' or 'b' followed by any character in the set [a-zA-Z0-9_]\n",
    "pattern10 = \"b\\w\" #<--handled hyphens should be inserted  between the [ab] and \\w \n",
    "pattern11 = \"\\wa\" # entries that contain an 'a' or 'b' preceded by any character in the set [a-zA-Z0-9_]\n",
    "pattern12 = \"\\wb\" # entries that contain an 'a' or 'b' preceded by any character in the set [a-zA-Z0-9_]\n",
    "pattern13 = \"[()]\"\n",
    "# remove space before 'a' at end of toes\n",
    "#investigate '\\d-', \n",
    "#'-(*)-', \n",
    "#' (16) ', \n",
    "#'---', <- may not exist in raw data\n",
    "#'\\d- ', \n",
    "#'- \\d', \n",
    "#transcription errors from excel (toes in date format,\n",
    "#'-\\d\\d\\d\\d' <- may not be in the data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll have to change this block if we add or remove toe patterns.\n",
    "This is not ideal and needs to be fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toe_pattern = pd.Series([*range(1,14)]) \n",
    "toe_pattern = make_str(toe_pattern)\n",
    "print(toe_pattern)\n",
    "\n",
    "toe_pattern_descr = pd.Series([pattern1,pattern2,pattern3,pattern4\n",
    "                               ,pattern5,pattern6,pattern7,pattern8\n",
    "                               ,pattern9,pattern10,pattern11,pattern12,pattern13])\n",
    "toe_pattern_descr = toe_pattern_descr.astype(str)\n",
    "print(toe_pattern_descr)\n",
    "\n",
    "toe_pattern_reference = pd.DataFrame({'toe_pattern': toe_pattern,'description':toe_pattern_descr})\n",
    "toe_pattern_reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first replace the string 'nan' with a null value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.toes=='nan','toes'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how many of these patterns we need to correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['toe_pattern'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use a for-loop to label the patterns \n",
    "(there's probably a better way to do this with pandas map or apply, but I'll have to figure this out, for now this is fast enough, but it could make a difference with a larger data set or with more patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(0,toe_pattern_reference.shape[0]):\n",
    "    tmp_pat_num = toe_pattern_reference.iloc[i,0]\n",
    "    tmp_pattern = toe_pattern_reference.iloc[i,1]\n",
    "    df = label_pattern(df,tmp_pat_num,tmp_pattern,'toe_pattern','toes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick summary of the number of observations for each pattern in the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toe_errors =df.toe_pattern.value_counts(dropna=False).reset_index()\\\n",
    ".rename(columns = {'index':'toe_pattern','toe_pattern':'observations'})\n",
    "toe_errors.loc[toe_errors.toe_pattern.isnull(),'toe_pattern'] = 'Not covered by current patterns'\n",
    "toe_errors_desc = toe_errors.merge(toe_pattern_reference,'left',on='toe_pattern')\n",
    "toe_errors_desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's make sure we've accounted for every row in the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accountedRows = toe_errors.observations.sum()\n",
    "totalRows = df.shape[0]\n",
    "notAccountedRows = df.shape[0] - toe_errors.observations.sum()\n",
    "print(\"\\nThere are {} rows accounted for in the patterns (including null values) and there {} rows in the full data set.\\\n",
    "  There are {} rows unaccounted for.\".format(accountedRows,totalRows,notAccountedRows))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And now we correct these patterns\n",
    "We'll preserve the original toe data in a column called \"toes_orig\" just in case.  We can drop this later, if we are comfortable with the changes.  The new toes will be labeled \"toes\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrections_config = {'01':{'action':'replace','pattern_b':\" \",'replacement':\"\\\"\\\"\"},\n",
    "            '02':{'action':'replace','pattern_b':\" \",'replacement':\"-\"},\n",
    "            '03':{'action':'replace','pattern_b':\"\\'\",'replacement':\"\\\"\\\"\"},\n",
    "            '04':{'action':'replace','pattern_b':\"/\",'replacement':\"-\"},\n",
    "            '05':{'action':'save','pattern_b':np.nan,'replacement':np.nan},\n",
    "            '06':{'action':'save','pattern_b':np.nan,'replacement':np.nan},\n",
    "            '07':{'action':'save','pattern_b':np.nan,'replacement':np.nan},\n",
    "            '08':{'action':'replace','pattern_b':\"^0\",'replacement':\"\\\"\\\"\"},\n",
    "            '09':{'action':'replace','pattern_b':'a','replacement':'-a'},\n",
    "            '10':{'action':'replace','pattern_b':'b','replacement':'-b'},          \n",
    "            '11':{'action':'replace','pattern_b':\"a\",'replacement':\"a-\"},\n",
    "            '12':{'action':'replace','pattern_b':\"b\",'replacement':\"b-\"},\n",
    "            '13':{'action':'replace','pattern_b':\"[()]\",'replacement':\"\\\"\\\"\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toe_errors_desc['action'] = toe_errors_desc.loc[toe_errors_desc.toe_pattern.str.len()==2].toe_pattern\\\n",
    ".map(lambda x: corrections_config[x]['action'],na_action='ignore')\n",
    "\n",
    "toe_errors_desc['replacement'] = toe_errors_desc.loc[toe_errors_desc.toe_pattern.str.len()==2].toe_pattern\\\n",
    ".map(lambda x: corrections_config[x]['replacement'],na_action='ignore')\n",
    "\n",
    "toe_errors_desc = toe_errors_desc.sort_values('toe_pattern').reset_index(drop=True)\n",
    "toe_errors_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,toe_errors_desc.shape[0]):\n",
    "    tmp_pat_num = toe_errors_desc.iloc[i,0]\n",
    "    tmp_pattern = toe_errors_desc.iloc[i,2]\n",
    "    action = toe_errors_desc.iloc[i,3]\n",
    "    tmp_replacement = toe_errors_desc.iloc[i,4]\n",
    "    tmp_x = df.loc[df.toe_pattern==tmp_pat_num,:]\n",
    "    \n",
    "    if action =='save':\n",
    "        tmp_filename = 'pattern'+tmp_pat_num+'.csv'\n",
    "        tmp_x.to_csv(tmp_filename)\n",
    "        print(\"Pattern {} successfully saved to {}.\".format(tmp_pattern,tmp_filename))\n",
    "    if action =='replace':\n",
    "        df.loc[df.toe_pattern==tmp_pat_num,'toes'] = replace_pattern(x=df.loc[df.toe_pattern==tmp_pat_num]\n",
    "                                                                     ,pattern = tmp_pat_num\n",
    "                                                                     ,pattern_b = tmp_pattern\n",
    "                                                                     ,source_col = 'toes'\n",
    "                                                                    ,replacement = tmp_replacement)\n",
    "        print(\"Pattern {} successfully replaced with {}.\".format(tmp_pattern,tmp_replacement))\n",
    "    else:\n",
    "        print(\"No direction provided for pattern {}.  No action was taken.\".format(tmp_pattern))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we confirm that the patterns we expect to have eliminated have indeed been eliminated from the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,toe_pattern_reference.shape[0]):\n",
    "    tmp_pattern = str(toe_pattern_reference.iloc[i,1])\n",
    "    report_pattern(df,tmp_pattern,'toes','Post-Correction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Sex'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Sex column\n",
    "[Top](#TOC)\n",
    "\n",
    "[Top Cleaning](#CleaningData)\n",
    "\n",
    "Next we move on to cleaning the \"sex\" column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we want to get an idea of the types of problems in the sex column.  We start by striping leading and trailing whitespaces.  You can see here that there were none in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.sex.str.len().unique())# returns unique lengths of sex\n",
    "df.sex=df.sex.str.strip()\n",
    "print(df.sex.str.len().unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify non \"m\" or \"f\" values and their frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "patterns_sex=\"m|f|NA\"\n",
    "non_matches=df.sex.loc[df.sex.str.match(patterns_sex)!=True]\n",
    "print(\"\\nThere are {} entries for sex which do not match the patterns {}:\"\\\n",
    "      .format(non_matches.shape[0],patterns_sex.split(\"|\")))\n",
    "non_matches.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify values to convert to NA, m, or f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex2NA=['adult','juv','nan']\n",
    "sex2m=['unm']\n",
    "df.loc[df.sex.isin(sex2NA)==True]\n",
    "print(df.sex.loc[df.sex.isin(sex2NA)==True].count())\n",
    "print(df.sex.loc[df.sex.isin(sex2m)==True].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the values to NA or m, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.loc[df.sex.isin(sex2m)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.sex.isin(sex2NA),'sex']=np.nan\n",
    "df.loc[df.sex.isin(sex2m),'sex']='m'\n",
    "print(df.sex.loc[df.sex.isin(sex2NA)==True].count())\n",
    "print(df.sex.loc[df.sex.isin(sex2m)==True].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set all remaining species and sex with \"?\" to NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df.species.str.contains('\\?')) & (df.species.notnull()),'species'] = np.nan\n",
    "df.loc[(df.sex.str.contains('\\?')) & (df.sex.notnull()),'sex'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Autotomized'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning autotmized column\n",
    "[Top](#TOC)\n",
    "\n",
    "[Top Cleaning](#CleaningData)\n",
    "\n",
    "Here we inspect and clean the autotomized columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autotomyDict = {False:'intact',True:'autotomized'}\n",
    "\n",
    "df.loc[:,'autotomized'] = df.loc[:,'autotomized'].map(autotomyDict)\n",
    "df.autotomized.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='NewRecap'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning new.recap column\n",
    "[Top](#TOC)\n",
    "\n",
    "[Top Cleaning](#CleaningData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try using a dict to do thing more efficiently\n",
    "newRecapKeep = ['recap', 'new', 'r', 'n']\n",
    "new = ['new','n']\n",
    "recap = ['recap','r']\n",
    "df.loc[~df['new.recap'].isin(newRecapKeep),'new.recap'] = np.nan\n",
    "df.loc[df['new.recap'].isin(new),'new.recap'] = 'new'\n",
    "df.loc[df['new.recap'].isin(recap),'new.recap'] = 'recap'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='AddCol'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding New Columns\n",
    "[Top](#TOC)\n",
    "\n",
    "We need to add new columns which we will use later in analyses:\n",
    "- [TL_SVL](#TlSvl)\n",
    "- [Mass_SVL](#MassSvl)\n",
    "- [Lizard Number](#LizardNumber)\n",
    "     - [assign lizard numbers](#Assign) \n",
    "     - [QC the lizard numbers](#QcLizNum) \n",
    "- [Days Since Capture](#daysSinceCapture)\n",
    "- [Number of Captures](#capture)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id= 'TlSvl'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TL_SVL \n",
    "[Top](#TOC)\n",
    "\n",
    "[Top Add Columns](#AddCol)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['tl_svl']=(df.tl/df.svl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='MassSvl'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mass_SVL\n",
    "[Top](#TOC)\n",
    "\n",
    "[Top Add Columns](#AddCol)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['mass_svl']=(df.mass/df.svl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id= 'LizardNumber'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lizard Number\n",
    "[Top](#TOC)\n",
    "\n",
    "[Top Add Columns](#AddCol)\n",
    "\n",
    "Here we use a set of functions to:\n",
    " - [assign lizard numbers](#Assign) to unique individuals (we repeat this step to ensure we have assigned all animals a number) and \n",
    " - [QC the numbers](#QcLizNum) assigned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Assign'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assign lizard numbers\n",
    "[Top](#TOC)\n",
    "\n",
    "[Top Add Columns](#AddCol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make a first attempt at assigning lizard numbers.  We use the *lizsort* function to identify the subset of rows from the original dataset which have sufficient information to allow us to make an automated decision about the uniqueness of the individuals identified in those rows.  We name that df *sortable*.  The unsortable data are saved to a path as a file, *unsortable.csv*.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sortable = lizsort(df, path = sourceDataBig)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we call the *mindate* function on *sortable*.  This identifies the earliest date at which each unique combination of *sortCriteria* are recorded in a new column, *initialCaptureDate*.  The default sortCriteria are of the variables *species*, *toes*, and *sex*.  This also calculates and adds a column for *year_diff*, the difference in years between the initial capture date and the date value in a given row. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sortable = mindate(sortable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we call a the function *smallest*, which is analogous to *mindate*, but groups data in *sortable* into unique combinations of *species*, *toes*, *sex*, and *initialCaptureDate* before assigning the smallest SVL value recorded for each group to a new column for that group, *smallest_svl*.  *smallest* then calculates a new column *svl_diff* which is analogous to *year_diff*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sortable = smallest(sortable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we call the *validate* function on *sortable*, which applies a series of validation tests to the data, sequentially numbers unique combinations of *sortCriteria* and returns a dict containing uniquely numbered individuals and summary data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_sort = validate(sortable)\n",
    "df_numbered1 = tmp_sort['val_data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second attempt to assign lizard numbers\n",
    "\n",
    "[Top](#TOC)\n",
    "\n",
    "[Top Add Columns](#AddCol)\n",
    "\n",
    "Here we make a second attempt at assigning lizard numbers to ensure that all lizards have been assigned.  This second attempt is focused on those rows which were unvalidated during the first attempt *n_val_data*.  Since these are already a subset fo those data which were sortabel, we need only call the *mindate*, *smallest*, and *validate* functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_val = mindate(tmp_sort['n_val_data'])\n",
    "n_val = smallest(n_val)\n",
    "df_numbered2 = validate(n_val)['val_data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since no rows remain unvalidated, we will not attempt a third validation.  We will simply append *df_numbered1* and *df_numbered2* to create *df_numbered* to create our full numbered dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numbered = df_numbered1.append(df_numbered2,ignore_index=True,sort=False)\n",
    "print(\"df:{}\\ndf_numbered1:{}\\ndf_numbered2:{}\\ndf_numbered:{}\".format(df.shape,df_numbered1.shape,df_numbered2.shape,\n",
    "                                                               df_numbered.shape))\n",
    "df_numbered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='QcLizNum'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QC of lizard numbers\n",
    "[Top](#TOC)\n",
    "\n",
    "[Top Add Columns](#AddCol)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we display the output data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numbered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify individuals that have same species and toes, but different sex for review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numbered = df_numbered.merge(df_numbered.groupby(['species','toes']).sex.nunique().reset_index()\\\n",
    "                       .rename(columns = {'sex':'sex_count'}),how = 'inner', on = ['species','toes'])\n",
    "df_numbered.loc[df_numbered.sex_count>1,:].to_csv('entries flagged with same species and toes diff sex.csv')\n",
    "print(\"{} rows have the same species and toes but different values for sex\"\\\n",
    "      .format(df_numbered.loc[df_numbered.sex_count>1,:].shape[0]))\n",
    "df_numbered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Lizard Numbers in the sample range from {} to {}.\"\\\n",
    "      .format(df_numbered.liznumber.min(),df_numbered.liznumber.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "possibleLizNum = set(range(int(df_numbered.liznumber.min()),int(df_numbered.liznumber.max())))\n",
    "actualLizNum = set(pd.Series(df_numbered.liznumber.unique()).dropna().apply(int))\n",
    "print(\"\\nThere are {} entries.  There are {} unique lizard numbers.\\\n",
    "\\n\\nThe liznumber ranges from {} to {}.\"\\\n",
    "  .format(df_numbered.shape[0],len(df_numbered.liznumber.unique())\\\n",
    "          ,df_numbered.liznumber.min(),df_numbered.liznumber.max()))\n",
    "\n",
    "missingLizNum = possibleLizNum - actualLizNum\n",
    "if len(missingLizNum)>0:\n",
    "    print(\"\\n\\nThe following numbers are not assigned to a lizard:\\n{}\"\\\n",
    "      .format(missingLizNum))\n",
    "else:\n",
    "    print(\"\\n\\nThere are no numbers which were not assigned.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='daysSinceCapture'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Days Since Capture\n",
    "[Top](#TOC)\n",
    "\n",
    "[Top Add Columns](#AddCol)\n",
    "\n",
    "*daysSinceCapture* identifies the number of days since the animal was captured"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='capture'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numbered.loc[:,'daysSinceCapture'] = (df_numbered.date - df_numbered.initialCaptureDate).dt.days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Capture Number\n",
    "[Top](#TOC)\n",
    "\n",
    "[Top Add Columns](#AddCol)\n",
    "\n",
    "*capture* identifies the number of times an animal has been captured prior to an entry.\n",
    "We will need to [QC capture](#QcCapture) as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to QC this this seems to be leading to several cases in which recap individuals that \n",
    "# only have one capture\n",
    "df_numbered['capture'] = df_numbered.sort_values(['liznumber','date'])\\\n",
    ".groupby(['liznumber']).daysSinceCapture.cumcount()+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df_numbered.loc[df_numbered.species.isin(['j','v'])].groupby('capture').capture.count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='yearstoolarge'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### years too large\n",
    "[Top](#TOC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "yeartoomuch = df_numbered.loc[df_numbered.year_diff>=5,'liznumber']\n",
    "checkyears = df_numbered.loc[df_numbered.liznumber.isin(yeartoomuch)].sort_values(['liznumber'])\n",
    "checkyears.to_csv('check years.csv')\n",
    "checkyears"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jarrovii = go.Histogram(x = df_numbered.loc[df_numbered.species.isin(['j'])].groupby('liznumber')\\\n",
    "                     .year_diff.max(),name = 'S. jarrovii')\n",
    "virgatus = go.Histogram(x = df_numbered.loc[df_numbered.species.isin(['v'])].groupby('liznumber')\\\n",
    "                     .year_diff.max(), name = 'S. virgatus')\n",
    "data = [jarrovii, virgatus]\n",
    "layout = go.Layout(\n",
    "    title = 'Number of Individuals by Years Between First and Last Capture 2000-2017',\n",
    "    titlefont = dict(\n",
    "        size = 20),\n",
    "    xaxis = dict(\n",
    "        dtick = 1,\n",
    "        title = 'Maximum Number of Years Since Initial Capture',\n",
    "        titlefont = dict(\n",
    "            size = 18)),\n",
    "    yaxis = dict(\n",
    "        title = 'Number of Lizards',\n",
    "        titlefont = dict(\n",
    "            size = 18))\n",
    ")\n",
    "fig = go.Figure(\n",
    "        data = data,\n",
    "        layout = layout)\n",
    "py.iplot(fig, filename = 'Frequency of Captures in Crystal Creek 2000 - 2017 (by species)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze work on this figure until we've resolved issues with calculation based on year\n",
    "# ADD HORIZONTAL LINES FOR EACH YEAR\n",
    "j_lizards = go.Scatter(x = df_numbered.loc[df_numbered.species.isin(['j'])].liznumber,\n",
    "                   y = df_numbered.loc[df_numbered.species.isin(['j'])]\\\n",
    "                      .groupby('liznumber').daysSinceCapture.max(), \n",
    "                     mode = 'markers', name='S. jarrovii')\n",
    "v_lizards = go.Scatter(x = df_numbered.loc[df_numbered.species.isin(['v'])].liznumber,\n",
    "                   y = df_numbered.loc[df_numbered.species.isin(['v'])]\\\n",
    "                      .groupby('liznumber').daysSinceCapture.max(), \n",
    "                     mode = 'markers', name='S. virgatus')\n",
    "# year1 = go.Scatter(x=[df_numbered.liznumber.min(),df_numbered.liznumber.max()],y = (365))\n",
    "# year2 = go.Scatter(y = 365*2)\n",
    "# year3 = go.Scatter(y = 365*3)\n",
    "# year4 = go.Scatter(y = 365*4)\n",
    "# year5 = go.Scatter(y = 365*5)\n",
    "# year6 = go.Scatter(y = 365*6)\n",
    "# year7 = go.Scatter(y = 365*7)\n",
    "# year8 = go.Scatter(y = 365*8)\n",
    "\n",
    "# data = [j_lizards, v_lizards, year1, year2, year3, year4, year5, year6, year7, year8]\n",
    "data = [j_lizards, v_lizards]\n",
    "layout = go.Layout(\n",
    "    title = 'Days Since Initial Capture in Crystal Creek 2000 - 2017',\n",
    "        titlefont = dict(\n",
    "            size = 20),\n",
    "    xaxis = dict(\n",
    "            title='Lizard Number',\n",
    "            titlefont=dict(\n",
    "                size=18)),\n",
    "    yaxis = dict(\n",
    "            title='Greatest Number of Days Since<br> Initial Capture',\n",
    "            titlefont=dict(\n",
    "                size=18)))\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename = 'Days Since Initial Capture in Crystal Creek 2000 - 2017')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfF = df_numbered.loc[(df_numbered.sex =='f' )& (df_numbered.species.isin(['j','v']))]\n",
    "dfM = df_numbered.loc[(df_numbered.sex =='m') & (df_numbered.species.isin(['j','v']))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze work on this figure until we've resolved issues with calculation based on year\n",
    "females = go.Scatter(\n",
    "    x = dfF.liznumber,\n",
    "    y = dfF.groupby('liznumber').daysSinceCapture.max(),\n",
    "    name = 'females',\n",
    "    mode = 'markers',\n",
    "    marker = dict(\n",
    "        color = 'rgba(152, 0, 0, .8)',\n",
    "        opacity = 0.75,\n",
    "        line = dict(\n",
    "            width = 2,\n",
    "            color = 'rgb(0, 0, 0)'\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "males = go.Scatter(\n",
    "    x = dfM.liznumber,\n",
    "    y = dfM.groupby('liznumber').daysSinceCapture.max(),\n",
    "    name = 'males',\n",
    "    mode = 'markers',\n",
    "    marker = dict(\n",
    "        color = 'rgba(255, 182, 193, .9)',\n",
    "        opacity = 0.75,\n",
    "        line = dict(\n",
    "            width = 2,\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "data = [females, males]\n",
    "\n",
    "layout = dict(title = 'Days Since Initial Capture in Crystal Creek 2000 - 2017 By Sex',\n",
    "              yaxis = dict(\n",
    "                  title='Greatest Number of Days Since<br> Initial Capture',\n",
    "                  titlefont=dict(\n",
    "                      size=18)\n",
    "              ),\n",
    "              xaxis = dict(zeroline = False)\n",
    "             )\n",
    "\n",
    "fig = dict(data=data, layout=layout)\n",
    "py.iplot(fig, filename='Days Since Initial Capture in Crystal Creek 2000 - 2017 By Sex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Something is wrong with 2006 and 2011 data.  Try grouping data by lizard numbers to address high numbers.\n",
    "# Freeze work on this figure until we've resolved issues with calculation based on year\n",
    "# Capture rate between Males and Females does not appear to be significantly different even before\n",
    "# statistical analysis\n",
    "males = go.Histogram(x = df_numbered.loc[(df_numbered.sex == 'm')& (df_numbered.species.isin(['j','v']))\n",
    "                                                                    ,'year']\n",
    "                     ,opacity= 0.75,name='males')\n",
    "females = go.Histogram(x = df_numbered.loc[(df_numbered.sex == 'f')& (df_numbered.species.isin(['j','v']))\n",
    "                                                                      ,'year']\n",
    "                       , opacity= 0.75, name = 'females')\n",
    "data = [males,females]\n",
    "py.iplot(data, filename = 'Distribution of Sex by Year in Crystal Creek 2000 - 2017')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numbered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_order = ['liznumber','date','initialCaptureDate',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.year.value_counts(dropna=False).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='QcCapture'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QC of Capture number and Recap status\n",
    "[Top](#TOC)\n",
    "\n",
    "[Top Add Columns](#AddCol)\n",
    "\n",
    "[Top Capture Number](#capture)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recapQuestion=df_numbered\\\n",
    ".loc[(df_numbered.capture==1 )&(df_numbered['new.recap']=='recap')&(df_numbered.species.isin(['j','v'])),:]\n",
    "print(\"There are {} instances in rows for which a lizard appears to have only one capture, \\\n",
    "but is listed as a recap.\\\n",
    "The distribution of these across years in the sample is as follows:\\n{}.\"\\\n",
    "      .format(recapQuestion.shape[0],recapQuestion.year.value_counts()))\n",
    "recapQuestion.to_csv(\"Questionable recaptures.csv\")#These individuals need to be rechecked in the raw notes\n",
    "recapQuestion.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recapQuestion.loc[recapQuestion.svl<54,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='exportFinal'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export Cleaned data\n",
    "[Top](#TOC)\n",
    "\n",
    "Now we export the cleaned data to a csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numbered = df_numbered.rename(index = str, columns = {'new.recap':'newRecap'})\n",
    "qc_drop_cols = df_numbered.columns[df_numbered.columns.str.contains('force|drop')]\n",
    "df_full = df_numbered.drop(qc_drop_cols,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "timestamp = (pd.to_datetime('now')-pd.Timedelta(hours=4))\n",
    "timestamp = str(timestamp)[:-10].replace(':','hrs')+'min'\n",
    "#path=''C:\\\\Users\\\\Christopher\\\\Google Drive\\\\TailDemography\\\\outputFiles\\\\''\n",
    "# path=outputBig\n",
    "filename = 'cleaned CC data 2000-2017_' + timestamp+ '.csv'\n",
    "# filename = path + '/cleaned CC data 2000-2017' + '.csv'\n",
    "df_full.to_csv(filename,index = False)\n",
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
