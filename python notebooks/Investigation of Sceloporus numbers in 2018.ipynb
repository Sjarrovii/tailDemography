{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of *Sceloporus jarrovii* and *S. virgatus* population sizes in Crystal Creek\n",
    "## George Middendorf and Christopher Agard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "- [Functions](#Functions)\n",
    "- [Purpose](#Purpose)\n",
    "- [Methods](#Methods)\n",
    "- [Results](#Results)\n",
    "- [Read in data](#Read-in-data)\n",
    "- [Set up Python](#Set-up-Python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions\n",
    "[Top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vocab_run\n",
    "\n",
    "[Top](#Table-of-Contents)\n",
    "\n",
    "[Functions](#Functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocab_run(x: list, connector_dict={1: None, 2: ' and ', 'run': ', '}):\n",
    "    \"\"\"\"vocab_run takes a list, joins its the first the elements with a separator placing a different separator between\n",
    "     the penultimate and final members of the list adn returns the result as a string\n",
    "     :param x: a list of strings to be concatenated\n",
    "     :param connector_dict: a dictionary with keys describing the size of the list and values indicating the type of\n",
    "     connectors separate the list elements.\n",
    "    \"\"\"\n",
    "    x = [str(el) for el in x]\n",
    "    if len(x) == 1:\n",
    "        vocab = x\n",
    "    else:\n",
    "        if len(x) == 2:\n",
    "            vocab = (connector_dict[len(x)]).join(x)\n",
    "        else:\n",
    "            connector = connector_dict['run']\n",
    "            connector_final = connector_dict[2]\n",
    "            vocab = connector.join(x[:-1])+connector_final+x[-1]\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "The intent of this notebook is to determine if the numbers of *Sceloporus jarrovii* and *S. virgatus* captured in Crystal Creek are in fact lower than in previous years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods\n",
    "We will begin by identifying a set of years in the existing cleaned data set during which the search period begins at a point in the year comparable to the start of the 2018 search period (i.e., mid-August). We will then determine the number of lizards captured for each year.  Finally, we will compare the number of lizards captured, looking for significant differences in the overall number of captures and the number of captures according to various demographics (sex, size-range, and previous capture status)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pandas packages will be our workhorse here, but we will need the os package for a few things too.  We'll also increase the maximum number of rows that are displyed on each print in order to make reviewing results easier. We'll be using plotly to creae any figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os,glob,time\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "plotly.tools.set_config_file(world_readable=True)\n",
    "\n",
    "pd.options.display.max_rows = 99999\n",
    "pd.options.display.max_columns = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will designate the paths from which to read data and to which output files should be written."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source Data\n",
    "sourceDataBig = 'S:/Chris/TailDemography/TailDemography/Raw Data'\n",
    "sourceBlack = 'C:/Users/test/Desktop'\n",
    "gdrivefileURL = \"https://docs.google.com/spreadsheets/d/1gJZ1S3-ToP2br8OkGmf1BVuutzvYJG4_cNG3DHM8avU/edit#gid=0\"\n",
    "\n",
    "#Output Data paths\n",
    "outputBig = 'S:/Chris/TailDemography/data'\n",
    "outBlack = 'C:/Users/test/Desktop'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need to change the working directory to the right paths and read in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Species</th>\n",
       "      <th>Toes</th>\n",
       "      <th>Date</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SVL</th>\n",
       "      <th>TL</th>\n",
       "      <th>RTL</th>\n",
       "      <th>Autotomized (autotomized=TRUE)</th>\n",
       "      <th>Mass</th>\n",
       "      <th>Paint Mark</th>\n",
       "      <th>Location</th>\n",
       "      <th>Meters</th>\n",
       "      <th>New/Recap</th>\n",
       "      <th>Painted</th>\n",
       "      <th>Sighting</th>\n",
       "      <th>Misc.</th>\n",
       "      <th>Vial</th>\n",
       "      <th>Time</th>\n",
       "      <th>Click Video</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8/15/2018</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bottom of site</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>IN: T=24.6C, H=57%, W=0.4 m/s; in at 0800; Mid...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Sj</td>\n",
       "      <td>10-11</td>\n",
       "      <td>8/15/2018</td>\n",
       "      <td>m</td>\n",
       "      <td>49.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>3.3</td>\n",
       "      <td>w1c</td>\n",
       "      <td>T right sb above bottom site entrance</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>new</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18-14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Sv</td>\n",
       "      <td>10-11</td>\n",
       "      <td>8/15/2018</td>\n",
       "      <td>f</td>\n",
       "      <td>57.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>6.0</td>\n",
       "      <td>w1a</td>\n",
       "      <td>bottom left wall</td>\n",
       "      <td>-7.0</td>\n",
       "      <td>new</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sj</td>\n",
       "      <td>9-10</td>\n",
       "      <td>8/15/2018</td>\n",
       "      <td>m</td>\n",
       "      <td>54.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>False</td>\n",
       "      <td>4.5</td>\n",
       "      <td>w2c</td>\n",
       "      <td>opp wall v wall v juniper crossing</td>\n",
       "      <td>80.0</td>\n",
       "      <td>new</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>shed recently loose scales T</td>\n",
       "      <td>18-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sj</td>\n",
       "      <td>10-12</td>\n",
       "      <td>8/15/2018</td>\n",
       "      <td>m</td>\n",
       "      <td>50.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>True</td>\n",
       "      <td>3.5</td>\n",
       "      <td>3c</td>\n",
       "      <td>mid R island</td>\n",
       "      <td>150.0</td>\n",
       "      <td>new</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>sex not recorded when caught on 15Aug, but rec...</td>\n",
       "      <td>18-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Species   Toes       Date  Sex   SVL    TL   RTL  \\\n",
       "0     NaN    NaN  8/15/2018  NaN   NaN   NaN   NaN   \n",
       "1      Sj  10-11  8/15/2018    m  49.0  71.0   0.0   \n",
       "2      Sv  10-11  8/15/2018    f  57.0  68.0   0.0   \n",
       "3      Sj   9-10  8/15/2018    m  54.0  57.0  20.0   \n",
       "4      Sj  10-12  8/15/2018    m  50.0  64.0   0.0   \n",
       "\n",
       "  Autotomized (autotomized=TRUE)  Mass Paint Mark  \\\n",
       "0                             NaN  NaN        NaN   \n",
       "1                            True  3.3        w1c   \n",
       "2                            True  6.0        w1a   \n",
       "3                           False  4.5        w2c   \n",
       "4                            True  3.5         3c   \n",
       "\n",
       "                                Location  Meters New/Recap Painted Sighting  \\\n",
       "0                         bottom of site     NaN       NaN     NaN      NaN   \n",
       "1  T right sb above bottom site entrance   -25.0       new     yes      NaN   \n",
       "2                       bottom left wall    -7.0       new     yes      NaN   \n",
       "3     opp wall v wall v juniper crossing    80.0       new     yes      NaN   \n",
       "4                           mid R island   150.0       new     yes      NaN   \n",
       "\n",
       "                                               Misc.   Vial Time Click Video  \n",
       "0  IN: T=24.6C, H=57%, W=0.4 m/s; in at 0800; Mid...    NaN  NaN         NaN  \n",
       "1                                                NaN  18-14  NaN         NaN  \n",
       "2                                                NaN  18-15  NaN         NaN  \n",
       "3                       shed recently loose scales T  18-12  NaN         NaN  \n",
       "4  sex not recorded when caught on 15Aug, but rec...  18-13  NaN         NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#make URL readable for pandas\n",
    "editableURL = gdrivefileURL.replace('edit#gid','export?format=csv&gid')\n",
    "df = pd.read_csv(editableURL)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "locationDict = {'bottom of site':-50,'R sb at brownR ^blackR ^ 1oakR':435,'on wall vwvjx just below fox den':100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "Index(['Species'], dtype='object')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-a34ad9a14c2d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;31m# df_captures_multi['SVL_diff']= df_captures_multi.apply()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mdf_captures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf_captures\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSpecies\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m'Sj'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Meters'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Toes'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Paint Mark'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Sex'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'SVL'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'TL'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'RTL'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Mass'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[1;33m.\u001b[0m\u001b[0mdrop_duplicates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Species'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Toes'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Paint Mark'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'SVL'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'2018 Captures Cheat Sheet.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mdrop_duplicates\u001b[1;34m(self, subset, keep, inplace)\u001b[0m\n\u001b[0;32m   4628\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4629\u001b[0m         \u001b[0minplace\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalidate_bool_kwarg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'inplace'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4630\u001b[1;33m         \u001b[0mduplicated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mduplicated\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkeep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkeep\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4631\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4632\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mduplicated\u001b[1;34m(self, subset, keep)\u001b[0m\n\u001b[0;32m   4681\u001b[0m         \u001b[0mdiff\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mIndex\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdifference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4682\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mdiff\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4683\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdiff\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4684\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4685\u001b[0m         vals = (col.values for name, col in self.iteritems()\n",
      "\u001b[1;31mKeyError\u001b[0m: Index(['Species'], dtype='object')"
     ]
    }
   ],
   "source": [
    "#Drop date\n",
    "df_captures = df.loc[(df.Sighting!='yes')&(df.Species.notna())&(df.Species!='Other')&(df.SVL.notna())&\n",
    "                     (df.Meters.notna()),\n",
    "                     ['Species', 'Toes','Sex', 'SVL', 'TL', 'RTL','Date',\n",
    "       'Autotomized (autotomized=TRUE) ', 'Mass', 'Paint Mark', 'Location',\n",
    "       'Meters']].sort_values(['Meters','Location'])\n",
    "df_captures.loc[df_captures['Autotomized (autotomized=TRUE) '],'RTL']=-1\n",
    "df_captures = df_captures.drop(columns='Autotomized (autotomized=TRUE) ')\n",
    "df_captures_multi = df_captures.groupby(['Species','Toes','Paint Mark']).Location.unique().reset_index()\\\n",
    ".merge(df_captures.groupby(['Species','Toes','Paint Mark']).Meters.unique().reset_index())\\\n",
    ".merge(df_captures.groupby(['Species','Toes','Paint Mark']).SVL.unique().reset_index()\n",
    "       ,on=['Species','Toes','Paint Mark'])\n",
    "\n",
    "# df_captures.loc[df_captures.Meters.notna()].to_csv('2018 Captures Cheat Sheet.csv'index=False)\n",
    "# df_captures_multi['SVL_diff']= df_captures_multi.apply()\n",
    "df_captures.loc[df_captures.Species=='Sj',['Meters','Toes','Paint Mark','Sex','SVL','TL','RTL','Mass']]\\\n",
    ".drop_duplicates(['Species','Toes','Paint Mark','SVL'])\\\n",
    ".to_csv('2018 Captures Cheat Sheet.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What to do with multiple captures?\n",
    "- Some of these are recaptured due to shedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 15 Species, Toes, Paint Mark combinations that have more than one record:\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Species</th>\n",
       "      <th>Toes</th>\n",
       "      <th>Paint Mark</th>\n",
       "      <th>Location</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Sj</td>\n",
       "      <td>10-19</td>\n",
       "      <td>w12c</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Sj</td>\n",
       "      <td>10-20</td>\n",
       "      <td>w13c.t</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Sj</td>\n",
       "      <td>5-11</td>\n",
       "      <td>w62c</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>Sj</td>\n",
       "      <td>7-11</td>\n",
       "      <td>w40c</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Sj</td>\n",
       "      <td>7-15</td>\n",
       "      <td>w44c</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>Sj</td>\n",
       "      <td>8-11</td>\n",
       "      <td>w29c</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Sj</td>\n",
       "      <td>8-13</td>\n",
       "      <td>w32c</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Sj</td>\n",
       "      <td>8-15</td>\n",
       "      <td>w33c</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Sj</td>\n",
       "      <td>8-19</td>\n",
       "      <td>w37c</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>Sj</td>\n",
       "      <td>9-11</td>\n",
       "      <td>w14c</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Sj</td>\n",
       "      <td>9-12</td>\n",
       "      <td>w16c</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>Sj</td>\n",
       "      <td>9-15</td>\n",
       "      <td>w21c</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>Sj</td>\n",
       "      <td>9-16</td>\n",
       "      <td>w22c</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Sj</td>\n",
       "      <td>9-18</td>\n",
       "      <td>w25c.t</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Sj</td>\n",
       "      <td>9-19</td>\n",
       "      <td>w26c</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Species   Toes Paint Mark  Location\n",
       "20      Sj  10-19       w12c         2\n",
       "21      Sj  10-20     w13c.t         2\n",
       "30      Sj   5-11       w62c         2\n",
       "49      Sj   7-11       w40c         2\n",
       "52      Sj   7-15       w44c         2\n",
       "56      Sj   8-11       w29c         2\n",
       "58      Sj   8-13       w32c         2\n",
       "59      Sj   8-15       w33c         2\n",
       "62      Sj   8-19       w37c         2\n",
       "67      Sj   9-11       w14c         2\n",
       "68      Sj   9-12       w16c         2\n",
       "72      Sj   9-15       w21c         2\n",
       "73      Sj   9-16       w22c         2\n",
       "74      Sj   9-18     w25c.t         2\n",
       "75      Sj   9-19       w26c         2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test=df_captures.groupby(['Species','Toes','Paint Mark']).Location.nunique().reset_index()\n",
    "print(\"There are {} Species, Toes, Paint Mark combinations that have more than one record:\\n\"\\\n",
    "      .format(test.loc[test.Location>1].shape[0]))\n",
    "test.loc[test.Location>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some of these cases are individuals who were captured multiple times (e.g., to repaint).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Species</th>\n",
       "      <th>Toes</th>\n",
       "      <th>Date</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SVL</th>\n",
       "      <th>TL</th>\n",
       "      <th>RTL</th>\n",
       "      <th>Autotomized (autotomized=TRUE)</th>\n",
       "      <th>Mass</th>\n",
       "      <th>Paint Mark</th>\n",
       "      <th>Location</th>\n",
       "      <th>Meters</th>\n",
       "      <th>New/Recap</th>\n",
       "      <th>Painted</th>\n",
       "      <th>Sighting</th>\n",
       "      <th>Misc.</th>\n",
       "      <th>Vial</th>\n",
       "      <th>Time</th>\n",
       "      <th>Click Video</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Species, Toes, Date, Sex, SVL, TL, RTL, Autotomized (autotomized=TRUE) , Mass, Paint Mark, Location, Meters, New/Recap, Painted, Sighting, Misc., Vial, Time, Click Video]\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Some of these cases are individuals who were captured multiple times (e.g., to repaint).\")\n",
    "df.loc[(df.Species=='Sj')&(df.Toes=='9-11')&(df['Paint Mark']=='w13c.t')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Some of these cases are individuals who were captured multiple times (e.g., to repaint).\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Species</th>\n",
       "      <th>Toes</th>\n",
       "      <th>Date</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SVL</th>\n",
       "      <th>TL</th>\n",
       "      <th>RTL</th>\n",
       "      <th>Autotomized (autotomized=TRUE)</th>\n",
       "      <th>Mass</th>\n",
       "      <th>Paint Mark</th>\n",
       "      <th>Location</th>\n",
       "      <th>Meters</th>\n",
       "      <th>New/Recap</th>\n",
       "      <th>Painted</th>\n",
       "      <th>Sighting</th>\n",
       "      <th>Misc.</th>\n",
       "      <th>Vial</th>\n",
       "      <th>Time</th>\n",
       "      <th>Click Video</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Sj</td>\n",
       "      <td>10-20</td>\n",
       "      <td>8/16/2018</td>\n",
       "      <td>m</td>\n",
       "      <td>80.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>17.5</td>\n",
       "      <td>w13c.t</td>\n",
       "      <td>H3</td>\n",
       "      <td>180.0</td>\n",
       "      <td>new</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bss</td>\n",
       "      <td>18-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>Sj</td>\n",
       "      <td>10-20</td>\n",
       "      <td>8/21/2018</td>\n",
       "      <td>m</td>\n",
       "      <td>79.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>16.3</td>\n",
       "      <td>w13c.t</td>\n",
       "      <td>6m v H6, 5m up wall above sb</td>\n",
       "      <td>202.0</td>\n",
       "      <td>recap</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Bshedding, lost \"13\" but \".t\" remains on T, do...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Species   Toes       Date Sex   SVL     TL  RTL  \\\n",
       "19       Sj  10-20  8/16/2018   m  80.0  111.0  0.0   \n",
       "161      Sj  10-20  8/21/2018   m  79.0  111.0  0.0   \n",
       "\n",
       "    Autotomized (autotomized=TRUE)   Mass Paint Mark  \\\n",
       "19                            False  17.5     w13c.t   \n",
       "161                           False  16.3     w13c.t   \n",
       "\n",
       "                         Location  Meters New/Recap Painted Sighting  \\\n",
       "19                             H3   180.0       new     yes      NaN   \n",
       "161  6m v H6, 5m up wall above sb   202.0     recap     yes      NaN   \n",
       "\n",
       "                                                 Misc.   Vial Time Click Video  \n",
       "19                                                 Bss  18-07  NaN         NaN  \n",
       "161  Bshedding, lost \"13\" but \".t\" remains on T, do...    NaN  NaN         NaN  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Some of these cases are individuals who were captured multiple times (e.g., to repaint).\")\n",
    "df.loc[(df.Species=='Sj')&(df.Toes=='10-20')&(df['Paint Mark']=='w13c.t')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are some that are separate individuals with the same toe and paint mark info.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Species</th>\n",
       "      <th>Toes</th>\n",
       "      <th>Date</th>\n",
       "      <th>Sex</th>\n",
       "      <th>SVL</th>\n",
       "      <th>TL</th>\n",
       "      <th>RTL</th>\n",
       "      <th>Autotomized (autotomized=TRUE)</th>\n",
       "      <th>Mass</th>\n",
       "      <th>Paint Mark</th>\n",
       "      <th>Location</th>\n",
       "      <th>Meters</th>\n",
       "      <th>New/Recap</th>\n",
       "      <th>Painted</th>\n",
       "      <th>Sighting</th>\n",
       "      <th>Misc.</th>\n",
       "      <th>Vial</th>\n",
       "      <th>Time</th>\n",
       "      <th>Click Video</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>Sj</td>\n",
       "      <td>5-11</td>\n",
       "      <td>9/7/2018</td>\n",
       "      <td>m</td>\n",
       "      <td>75.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>15.0</td>\n",
       "      <td>w62c</td>\n",
       "      <td>left wall at lizardR</td>\n",
       "      <td>135.0</td>\n",
       "      <td>new</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18-71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>Sj</td>\n",
       "      <td>5-11</td>\n",
       "      <td>9/8/2018</td>\n",
       "      <td>f</td>\n",
       "      <td>49.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>True</td>\n",
       "      <td>3.7</td>\n",
       "      <td>w62c</td>\n",
       "      <td>R sb 5m ^ slab</td>\n",
       "      <td>268.0</td>\n",
       "      <td>new</td>\n",
       "      <td>yes</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>18-71</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Species  Toes      Date Sex   SVL     TL   RTL  \\\n",
       "508      Sj  5-11  9/7/2018   m  75.0  105.0   0.0   \n",
       "519      Sj  5-11  9/8/2018   f  49.0   40.0  22.0   \n",
       "\n",
       "    Autotomized (autotomized=TRUE)   Mass Paint Mark              Location  \\\n",
       "508                           False  15.0       w62c  left wall at lizardR   \n",
       "519                            True   3.7       w62c        R sb 5m ^ slab   \n",
       "\n",
       "     Meters New/Recap Painted Sighting Misc.   Vial Time Click Video  \n",
       "508   135.0       new     yes      NaN   NaN  18-71  NaN         NaN  \n",
       "519   268.0       new     yes      NaN   NaN  18-71  NaN         NaN  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"There are some that are separate individuals with the same toe and paint mark info.\")\n",
    "df.loc[(df.Species=='Sj')&(df.Toes=='5-11')&(df['Paint Mark']=='w62c')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "os.chdir(sourceDataBig)\n",
    "\n",
    "# combinedFiles = glob.glob('cleaned CC data 2000-2017*')\n",
    "combinedFiles = 'cleaned CC data 2000-2017_2019-01-07 21hrs27min.csv'\n",
    "combinedFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'CC Data 2018 - Data Entry Sheet.csv' does not exist: b'CC Data 2018 - Data Entry Sheet.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-0eaa660f860a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdfPrev\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'CC Data 2018 - Data Entry Sheet.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdfPrev\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdfPrev\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'2000-2017 species included:\\n{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdfPrev\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspecies\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 429\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1122\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1123\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1124\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1852\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1855\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'CC Data 2018 - Data Entry Sheet.csv' does not exist: b'CC Data 2018 - Data Entry Sheet.csv'"
     ]
    }
   ],
   "source": [
    "dfPrev=pd.read_csv('CC Data 2018 - Data Entry Sheet.csv')\n",
    "dfPrev.columns = dfPrev.columns.str.lower()\n",
    "print('2000-2017 species included:\\n{}'.format(dfPrev.species.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we read in the 2018 data set and change its columns headers to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] File b'CC Data 2018 - Data Entry Sheet.csv' does not exist: b'CC Data 2018 - Data Entry Sheet.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-e951440df5cb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdf2018\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'CC Data 2018 - Data Entry Sheet.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf2018\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf2018\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'2018 species included:\\n{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf2018\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspecies\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, tupleize_cols, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    700\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[0;32m    701\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 702\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    703\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    704\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    427\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 429\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    430\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'has_index_names'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    894\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 895\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    896\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    897\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1120\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'c'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1121\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'c'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1122\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1123\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1124\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'python'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1851\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'usecols'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1852\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1853\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1854\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1855\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] File b'CC Data 2018 - Data Entry Sheet.csv' does not exist: b'CC Data 2018 - Data Entry Sheet.csv'"
     ]
    }
   ],
   "source": [
    "df2018=pd.read_csv('CC Data 2018 - Data Entry Sheet.csv')\n",
    "df2018.columns = df2018.columns.str.lower()\n",
    "print('2018 species included:\\n{}'.format(df2018.species.unique()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will only consider *S. jarrovii* and *S. virgatus* for our comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dfPrev' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-ee5f70892227>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdfPrev\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdfPrev\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdfPrev\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspecies\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'j'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'v'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'2000-2017 species included:\\n{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdfPrev\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspecies\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdf2018\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf2018\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf2018\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspecies\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Sj'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Sv'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'2018 species included:\\n{}'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf2018\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspecies\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dfPrev' is not defined"
     ]
    }
   ],
   "source": [
    "dfPrev = dfPrev.loc[dfPrev.species.isin(['j','v'])]\n",
    "print('2000-2017 species included:\\n{}'.format(dfPrev.species.unique()))\n",
    "\n",
    "df2018 = df2018.loc[df2018.species.isin(['Sj','Sv'])]\n",
    "print('2018 species included:\\n{}'.format(df2018.species.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to coerce the dates in both data sets to datetime objects.  In order to compare across years in a figure we will also have to create a new variable, __week__, which represents that date as the week of the year (*i.e.*, from 1 to 52). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dfPrev' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-5d22e10f4b37>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdfPrev\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdfPrev\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'coerce'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mdf2018\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf2018\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'coerce'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdfPrev\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'week'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdfPrev\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweekofyear\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdf2018\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'week'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdf2018\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweekofyear\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dfPrev' is not defined"
     ]
    }
   ],
   "source": [
    "dfPrev.date = pd.to_datetime(dfPrev.date,errors='coerce')\n",
    "df2018.date = pd.to_datetime(df2018.date,errors='coerce')\n",
    "\n",
    "dfPrev['week'] = dfPrev.date.dt.weekofyear\n",
    "df2018['week'] = df2018.date.dt.weekofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dfPrev' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-4f42f523eae4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdfPrev\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweek\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'dfPrev' is not defined"
     ]
    }
   ],
   "source": [
    "dfPrev.week.sort_values().unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can graph the timeperiods over which we captured lizards in both data sets to see which years overlapped with 2018.  We wil use a series of horizontal violin plots for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dfPrev' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-1bff5ea8e3f8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my2000\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBox\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdfPrev\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdfPrev\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myear\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2000\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"week\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m'2000'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mboxpoints\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'all'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0my2001\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBox\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdfPrev\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdfPrev\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myear\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2001\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"week\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m'2001'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mboxpoints\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'all'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0my2002\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBox\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdfPrev\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdfPrev\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myear\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2002\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"week\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m'2002'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mboxpoints\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'all'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0my2003\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBox\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdfPrev\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdfPrev\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myear\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2003\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"week\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m'2003'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mboxpoints\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'all'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0my2004\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBox\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdfPrev\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdfPrev\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myear\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2004\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"week\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;34m'2004'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mboxpoints\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'all'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dfPrev' is not defined"
     ]
    }
   ],
   "source": [
    "y2000 = go.Box(x=dfPrev.loc[dfPrev.year == 2000,\"week\"],name= '2000',boxpoints = 'all')\n",
    "y2001 = go.Box(x=dfPrev.loc[dfPrev.year == 2001,\"week\"],name= '2001',boxpoints = 'all')\n",
    "y2002 = go.Box(x=dfPrev.loc[dfPrev.year == 2002,\"week\"],name= '2002',boxpoints = 'all')\n",
    "y2003 = go.Box(x=dfPrev.loc[dfPrev.year == 2003,\"week\"],name= '2003',boxpoints = 'all')\n",
    "y2004 = go.Box(x=dfPrev.loc[dfPrev.year == 2004,\"week\"],name= '2004',boxpoints = 'all')\n",
    "y2005 = go.Box(x=dfPrev.loc[dfPrev.year == 2005,\"week\"],name= '2005',boxpoints = 'all')\n",
    "y2006 = go.Box(x=dfPrev.loc[dfPrev.year == 2006,\"week\"],name= '2006',boxpoints = 'all')\n",
    "y2007 = go.Box(x=dfPrev.loc[dfPrev.year == 2007,\"week\"],name= '2007',boxpoints = 'all')\n",
    "y2008 = go.Box(x=dfPrev.loc[dfPrev.year == 2008,\"week\"],name= '2008',boxpoints = 'all')\n",
    "y2009 = go.Box(x=dfPrev.loc[dfPrev.year == 2009,\"week\"],name= '2009',boxpoints = 'all')\n",
    "y2010 = go.Box(x=dfPrev.loc[dfPrev.year == 2010,\"week\"],name= '2010',boxpoints = 'all')\n",
    "y2011 = go.Box(x=dfPrev.loc[dfPrev.year == 2011,\"week\"],name= '2011',boxpoints = 'all')\n",
    "y2012 = go.Box(x=dfPrev.loc[dfPrev.year == 2012,\"week\"],name= '2012',boxpoints = 'all')\n",
    "y2013 = go.Box(x=dfPrev.loc[dfPrev.year == 2013,\"week\"],name= '2013',boxpoints = 'all')\n",
    "y2014 = go.Box(x=dfPrev.loc[dfPrev.year == 2014,\"week\"],name= '2014',boxpoints = 'all')\n",
    "y2015 = go.Box(x=dfPrev.loc[dfPrev.year == 2015,\"week\"],name= '2015',boxpoints = 'all')\n",
    "y2016 = go.Box(x=dfPrev.loc[dfPrev.year == 2016,\"week\"],name= '2016',boxpoints = 'all')\n",
    "y2017 = go.Box(x=dfPrev.loc[dfPrev.year == 2017,\"week\"],name= '2017',boxpoints = 'all')\n",
    "y2018 = go.Box(x=df2018.week,name= '2018',boxpoints = 'all')\n",
    "\n",
    "dataPrev = [y2000,y2001,y2002,y2003,y2004,\n",
    "        y2005,y2006,y2007,y2008,y2009,\n",
    "        y2010,y2011,y2012,y2013,y2014,\n",
    "        y2015,y2016,y2017,y2018]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title = 'Distribution of Captures in Crystal Creek by Year',\n",
    "    titlefont = dict(\n",
    "        size = 20),\n",
    "    yaxis = dict(\n",
    "        title = 'Year',\n",
    "        dtick = 1,\n",
    "        titlefont = dict(\n",
    "            size = 18)),\n",
    "    xaxis = dict(\n",
    "        title = 'Week of the Year',\n",
    "        dtick = 1,\n",
    "        titlefont = dict(\n",
    "            size = 18)))\n",
    "\n",
    "fig = go.Figure(\n",
    "    data = dataPrev, \n",
    "    layout = layout)\n",
    "\n",
    "py.iplot(fig, filename = 'Boxplot of Captures in CC by Week in the Year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like there's no year that completely overlaps the 2018 field season between 2000 and 2017.  The closet years end 2 weeks before the 2018 season started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get an idea of which year is the closest, let's look at the distance between the median week for captures and find those with the closest distance to 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dfPrev' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-12a425237bba>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdistance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdfPrev\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'year'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mdf2018\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweek\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweek\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmedian\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mreset_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;34m'distMed'\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdistance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myear\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdistance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myear\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dfPrev' is not defined"
     ]
    }
   ],
   "source": [
    "distance = dfPrev.groupby('year').apply(lambda x: df2018.week.median() - x.week.median())\\\n",
    ".reset_index()\\\n",
    ".rename(columns={0:'distMed'})\n",
    "\n",
    "distance.year = distance.year.astype(int)\n",
    "\n",
    "nearest = distance[distance.distMed <= distance.distMed.min()]\n",
    "\n",
    "print('The smallest median distance between any of the comparison years and the 2018 field season is {}.\\\n",
    "  The associated years are {}.'.format(int(distance.distMed.min()),prettyprint(nearest.year)))\n",
    "\n",
    "distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'nearest' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-829399b2c2a8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mnearest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myear\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'nearest' is not defined"
     ]
    }
   ],
   "source": [
    "[int(i) for i in nearest.year]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'distance' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-0edf76aa0827>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgo\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mScatter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdistance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0myear\u001b[0m \u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdistance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistMed\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'markers'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m layout = go.Layout(\n\u001b[0;32m      4\u001b[0m     \u001b[0mtitle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'Distance Between Median Week and 2018 Median Week'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     titlefont = dict(\n",
      "\u001b[1;31mNameError\u001b[0m: name 'distance' is not defined"
     ]
    }
   ],
   "source": [
    "data = go.Scatter(x = distance.year ,y=distance.distMed, mode = 'markers')\n",
    "\n",
    "layout = go.Layout(\n",
    "    title = 'Distance Between Median Week and 2018 Median Week',\n",
    "    titlefont = dict(\n",
    "        size = 20),\n",
    "    xaxis = dict(\n",
    "        title = 'Year',\n",
    "        titlefont = dict(\n",
    "        size = 18)),\n",
    "    yaxis = dict(\n",
    "        title = 'Distance in Weeks Between Median Week and Median Week for 2018 Season',\n",
    "        titlefont = dict(\n",
    "            size = 18))\n",
    ")\n",
    "\n",
    "fig = go.Figure(data = data, layout = layout)\n",
    "\n",
    "py.iplot(fig,filename = 'Scatter Plot of Distance Between Median Week and 2018 Median Week' )\n",
    "# plot_url = py.plot(data, filename='Scatter Plot of Distance Between Median Week and 2018 Median Week')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
