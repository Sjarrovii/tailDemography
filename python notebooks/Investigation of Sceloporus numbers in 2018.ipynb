{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of *Sceloporus jarrovii* and *S. virgatus* population sizes in Crystal Creek\n",
    "## George Middendorf and Christopher Agard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "\n",
    "- [Functions](#Functions)\n",
    "- [Purpose](#Purpose)\n",
    "- [Methods](#Methods)\n",
    "- [Results](#Results)\n",
    "- [Read in data](#Read-in-data)\n",
    "- [Set up Python](#Set-up-Python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions\n",
    "[Top](#Table-of-Contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## vocab_run\n",
    "\n",
    "[Top](#Table-of-Contents)\n",
    "\n",
    "[Functions](#Functions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vocab_run(x: list, connector_dict={1: None, 2: ' and ', 'run': ', '}):\n",
    "    \"\"\"\"vocab_run takes a list, joins its the first the elements with a separator placing a different separator between\n",
    "     the penultimate and final members of the list adn returns the result as a string\n",
    "     :param x: a list of strings to be concatenated\n",
    "     :param connector_dict: a dictionary with keys describing the size of the list and values indicating the type of\n",
    "     connectors separate the list elements.\n",
    "    \"\"\"\n",
    "    x = [str(el) for el in x]\n",
    "    if len(x) == 1:\n",
    "        vocab = x\n",
    "    else:\n",
    "        if len(x) == 2:\n",
    "            vocab = (connector_dict[len(x)]).join(x)\n",
    "        else:\n",
    "            connector = connector_dict['run']\n",
    "            connector_final = connector_dict[2]\n",
    "            vocab = connector.join(x[:-1])+connector_final+x[-1]\n",
    "    return vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Purpose\n",
    "The intent of this notebook is to determine if the numbers of *Sceloporus jarrovii* and *S. virgatus* captured in Crystal Creek are in fact lower than in previous years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods\n",
    "We will begin by identifying a set of years in the existing cleaned data set during which the search period begins at a point in the year comparable to the start of the 2018 search period (i.e., mid-August). We will then determine the number of lizards captured for each year.  Finally, we will compare the number of lizards captured, looking for significant differences in the overall number of captures and the number of captures according to various demographics (sex, size-range, and previous capture status)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pandas packages will be our workhorse here, but we will need the os package for a few things too.  We'll also increase the maximum number of rows that are displyed on each print in order to make reviewing results easier. We'll be using plotly to creae any figures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "\nThe plotly.plotly module is deprecated,\nplease install the chart-studio package and use the\nchart_studio.plotly module instead. \n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-f812937b1f13>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mglob\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplotly\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mplotly\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_objs\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mgo\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\plotly\\plotly\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m_plotly_future_\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_chart_studio_error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0m_chart_studio_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"plotly\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\_plotly_future_\\__init__.py\u001b[0m in \u001b[0;36m_chart_studio_error\u001b[1;34m(submodule)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[0mchart_studio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0msubmodule\u001b[0m\u001b[1;33m}\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0minstead\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     48\u001b[0m \"\"\".format(\n\u001b[1;32m---> 49\u001b[1;33m             \u001b[0msubmodule\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msubmodule\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     50\u001b[0m         )\n\u001b[0;32m     51\u001b[0m     )\n",
      "\u001b[1;31mImportError\u001b[0m: \nThe plotly.plotly module is deprecated,\nplease install the chart-studio package and use the\nchart_studio.plotly module instead. \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import os,glob,time\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "plotly.tools.set_config_file(world_readable=True)\n",
    "\n",
    "pd.options.display.max_rows = 99999\n",
    "pd.options.display.max_columns = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will designate the paths from which to read data and to which output files should be written."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source Data\n",
    "sourceDataBig = 'S:/Chris/TailDemography/TailDemography/Raw Data'\n",
    "sourceBlack = 'C:/Users/test/Desktop'\n",
    "gdrivefileURL = \"https://docs.google.com/spreadsheets/d/1gJZ1S3-ToP2br8OkGmf1BVuutzvYJG4_cNG3DHM8avU/edit#gid=0\"\n",
    "\n",
    "#Output Data paths\n",
    "outputBig = 'S:/Chris/TailDemography/data'\n",
    "outBlack = 'C:/Users/test/Desktop'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need to change the working directory to the right paths and read in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#make URL readable for pandas\n",
    "editableURL = gdrivefileURL.replace('edit#gid','export?format=csv&gid')\n",
    "df = pd.read_csv(editableURL)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "locationDict = {'bottom of site':-50,'R sb at brownR ^blackR ^ 1oakR':435,'on wall vwvjx just below fox den':100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Drop date\n",
    "df_captures = df.loc[(df.Sighting!='yes')&(df.Species.notna())&(df.Species!='Other')&(df.SVL.notna())&\n",
    "                     (df.Meters.notna()),\n",
    "                     ['Species', 'Toes','Sex', 'SVL', 'TL', 'RTL','Date',\n",
    "       'Autotomized (autotomized=TRUE) ', 'Mass', 'Paint Mark', 'Location',\n",
    "       'Meters']].sort_values(['Meters','Location'])\n",
    "df_captures.loc[df_captures['Autotomized (autotomized=TRUE) '],'RTL']=-1\n",
    "df_captures = df_captures.drop(columns='Autotomized (autotomized=TRUE) ')\n",
    "df_captures_multi = df_captures.groupby(['Species','Toes','Paint Mark']).Location.unique().reset_index()\\\n",
    ".merge(df_captures.groupby(['Species','Toes','Paint Mark']).Meters.unique().reset_index())\\\n",
    ".merge(df_captures.groupby(['Species','Toes','Paint Mark']).SVL.unique().reset_index()\n",
    "       ,on=['Species','Toes','Paint Mark'])\n",
    "\n",
    "# df_captures.loc[df_captures.Meters.notna()].to_csv('2018 Captures Cheat Sheet.csv'index=False)\n",
    "# df_captures_multi['SVL_diff']= df_captures_multi.apply()\n",
    "df_captures.loc[df_captures.Species=='Sj',['Meters','Toes','Paint Mark','Sex','SVL','TL','RTL','Mass']]\\\n",
    ".drop_duplicates(['Species','Toes','Paint Mark','SVL'])\\\n",
    ".to_csv('2018 Captures Cheat Sheet.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What to do with multiple captures?\n",
    "- Some of these are recaptured due to shedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test=df_captures.groupby(['Species','Toes','Paint Mark']).Location.nunique().reset_index()\n",
    "print(\"There are {} Species, Toes, Paint Mark combinations that have more than one record:\\n\"\\\n",
    "      .format(test.loc[test.Location>1].shape[0]))\n",
    "test.loc[test.Location>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Some of these cases are individuals who were captured multiple times (e.g., to repaint).\")\n",
    "df.loc[(df.Species=='Sj')&(df.Toes=='9-11')&(df['Paint Mark']=='w13c.t')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Some of these cases are individuals who were captured multiple times (e.g., to repaint).\")\n",
    "df.loc[(df.Species=='Sj')&(df.Toes=='10-20')&(df['Paint Mark']=='w13c.t')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"There are some that are separate individuals with the same toe and paint mark info.\")\n",
    "df.loc[(df.Species=='Sj')&(df.Toes=='5-11')&(df['Paint Mark']=='w62c')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "os.chdir(sourceDataBig)\n",
    "\n",
    "# combinedFiles = glob.glob('cleaned CC data 2000-2017*')\n",
    "combinedFiles = 'cleaned CC data 2000-2017_2019-01-07 21hrs27min.csv'\n",
    "combinedFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPrev=pd.read_csv('CC Data 2018 - Data Entry Sheet.csv')\n",
    "dfPrev.columns = dfPrev.columns.str.lower()\n",
    "print('2000-2017 species included:\\n{}'.format(dfPrev.species.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we read in the 2018 data set and change its columns headers to lowercase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2018=pd.read_csv('CC Data 2018 - Data Entry Sheet.csv')\n",
    "df2018.columns = df2018.columns.str.lower()\n",
    "print('2018 species included:\\n{}'.format(df2018.species.unique()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will only consider *S. jarrovii* and *S. virgatus* for our comparisons."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPrev = dfPrev.loc[dfPrev.species.isin(['j','v'])]\n",
    "print('2000-2017 species included:\\n{}'.format(dfPrev.species.unique()))\n",
    "\n",
    "df2018 = df2018.loc[df2018.species.isin(['Sj','Sv'])]\n",
    "print('2018 species included:\\n{}'.format(df2018.species.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to coerce the dates in both data sets to datetime objects.  In order to compare across years in a figure we will also have to create a new variable, __week__, which represents that date as the week of the year (*i.e.*, from 1 to 52). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPrev.date = pd.to_datetime(dfPrev.date,errors='coerce')\n",
    "df2018.date = pd.to_datetime(df2018.date,errors='coerce')\n",
    "\n",
    "dfPrev['week'] = dfPrev.date.dt.weekofyear\n",
    "df2018['week'] = df2018.date.dt.weekofyear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPrev.week.sort_values().unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can graph the timeperiods over which we captured lizards in both data sets to see which years overlapped with 2018.  We wil use a series of horizontal violin plots for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y2000 = go.Box(x=dfPrev.loc[dfPrev.year == 2000,\"week\"],name= '2000',boxpoints = 'all')\n",
    "y2001 = go.Box(x=dfPrev.loc[dfPrev.year == 2001,\"week\"],name= '2001',boxpoints = 'all')\n",
    "y2002 = go.Box(x=dfPrev.loc[dfPrev.year == 2002,\"week\"],name= '2002',boxpoints = 'all')\n",
    "y2003 = go.Box(x=dfPrev.loc[dfPrev.year == 2003,\"week\"],name= '2003',boxpoints = 'all')\n",
    "y2004 = go.Box(x=dfPrev.loc[dfPrev.year == 2004,\"week\"],name= '2004',boxpoints = 'all')\n",
    "y2005 = go.Box(x=dfPrev.loc[dfPrev.year == 2005,\"week\"],name= '2005',boxpoints = 'all')\n",
    "y2006 = go.Box(x=dfPrev.loc[dfPrev.year == 2006,\"week\"],name= '2006',boxpoints = 'all')\n",
    "y2007 = go.Box(x=dfPrev.loc[dfPrev.year == 2007,\"week\"],name= '2007',boxpoints = 'all')\n",
    "y2008 = go.Box(x=dfPrev.loc[dfPrev.year == 2008,\"week\"],name= '2008',boxpoints = 'all')\n",
    "y2009 = go.Box(x=dfPrev.loc[dfPrev.year == 2009,\"week\"],name= '2009',boxpoints = 'all')\n",
    "y2010 = go.Box(x=dfPrev.loc[dfPrev.year == 2010,\"week\"],name= '2010',boxpoints = 'all')\n",
    "y2011 = go.Box(x=dfPrev.loc[dfPrev.year == 2011,\"week\"],name= '2011',boxpoints = 'all')\n",
    "y2012 = go.Box(x=dfPrev.loc[dfPrev.year == 2012,\"week\"],name= '2012',boxpoints = 'all')\n",
    "y2013 = go.Box(x=dfPrev.loc[dfPrev.year == 2013,\"week\"],name= '2013',boxpoints = 'all')\n",
    "y2014 = go.Box(x=dfPrev.loc[dfPrev.year == 2014,\"week\"],name= '2014',boxpoints = 'all')\n",
    "y2015 = go.Box(x=dfPrev.loc[dfPrev.year == 2015,\"week\"],name= '2015',boxpoints = 'all')\n",
    "y2016 = go.Box(x=dfPrev.loc[dfPrev.year == 2016,\"week\"],name= '2016',boxpoints = 'all')\n",
    "y2017 = go.Box(x=dfPrev.loc[dfPrev.year == 2017,\"week\"],name= '2017',boxpoints = 'all')\n",
    "y2018 = go.Box(x=df2018.week,name= '2018',boxpoints = 'all')\n",
    "\n",
    "dataPrev = [y2000,y2001,y2002,y2003,y2004,\n",
    "        y2005,y2006,y2007,y2008,y2009,\n",
    "        y2010,y2011,y2012,y2013,y2014,\n",
    "        y2015,y2016,y2017,y2018]\n",
    "\n",
    "layout = go.Layout(\n",
    "    title = 'Distribution of Captures in Crystal Creek by Year',\n",
    "    titlefont = dict(\n",
    "        size = 20),\n",
    "    yaxis = dict(\n",
    "        title = 'Year',\n",
    "        dtick = 1,\n",
    "        titlefont = dict(\n",
    "            size = 18)),\n",
    "    xaxis = dict(\n",
    "        title = 'Week of the Year',\n",
    "        dtick = 1,\n",
    "        titlefont = dict(\n",
    "            size = 18)))\n",
    "\n",
    "fig = go.Figure(\n",
    "    data = dataPrev, \n",
    "    layout = layout)\n",
    "\n",
    "py.iplot(fig, filename = 'Boxplot of Captures in CC by Week in the Year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like there's no year that completely overlaps the 2018 field season between 2000 and 2017.  The closet years end 2 weeks before the 2018 season started."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get an idea of which year is the closest, let's look at the distance between the median week for captures and find those with the closest distance to 2018."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance = dfPrev.groupby('year').apply(lambda x: df2018.week.median() - x.week.median())\\\n",
    ".reset_index()\\\n",
    ".rename(columns={0:'distMed'})\n",
    "\n",
    "distance.year = distance.year.astype(int)\n",
    "\n",
    "nearest = distance[distance.distMed <= distance.distMed.min()]\n",
    "\n",
    "print('The smallest median distance between any of the comparison years and the 2018 field season is {}.\\\n",
    "  The associated years are {}.'.format(int(distance.distMed.min()),prettyprint(nearest.year)))\n",
    "\n",
    "distance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[int(i) for i in nearest.year]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = go.Scatter(x = distance.year ,y=distance.distMed, mode = 'markers')\n",
    "\n",
    "layout = go.Layout(\n",
    "    title = 'Distance Between Median Week and 2018 Median Week',\n",
    "    titlefont = dict(\n",
    "        size = 20),\n",
    "    xaxis = dict(\n",
    "        title = 'Year',\n",
    "        titlefont = dict(\n",
    "        size = 18)),\n",
    "    yaxis = dict(\n",
    "        title = 'Distance in Weeks Between Median Week and Median Week for 2018 Season',\n",
    "        titlefont = dict(\n",
    "            size = 18))\n",
    ")\n",
    "\n",
    "fig = go.Figure(data = data, layout = layout)\n",
    "\n",
    "py.iplot(fig,filename = 'Scatter Plot of Distance Between Median Week and 2018 Median Week' )\n",
    "# plot_url = py.plot(data, filename='Scatter Plot of Distance Between Median Week and 2018 Median Week')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
