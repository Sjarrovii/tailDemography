{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning CC data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This python notebook operates on a csv created after editing in open refine and is designed to finish cleaning columns of interest which were easier to clean in python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setting up Python\n",
    "\n",
    "Here we import necessary packages. \n",
    "This chunk may take a while."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'functions'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-c579a32e418b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mfunctions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mliz_clean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mliz_number\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mlizsort\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmindate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msmallest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mvalidate\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mfunctions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mliz_clean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mliz_toes\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmake_str\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel_pattern\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreplace_pattern\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mreport_pattern\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'functions'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from functions.liz_clean.liz_number import lizsort,mindate,smallest,validate\n",
    "from functions.liz_clean.liz_toes import make_str,label_pattern, replace_pattern,report_pattern\n",
    "\n",
    "import plotly\n",
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "\n",
    "plotly.tools.set_config_file(world_readable=True)\n",
    "\n",
    "# increase print limit\n",
    "pd.options.display.max_rows = 99999\n",
    "pd.options.display.max_columns = 50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions necessary for this notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use this chunk to read data from local folder on Chris' machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source Data\n",
    "sourceDataPers = 'C:/Users/Christopher/Google Drive/TailDemography/outputFiles'\n",
    "sourceDataBig = 'S:/Chris/TailDemography/combined data'\n",
    "\n",
    "#Output Data paths\n",
    "outputPers = 'C:/Users/Christopher/Google Drive/TailDemography/outputFiles'\n",
    "outputBig = 'S:/Chris/TailDemography/data'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>species</th>\n",
       "      <th>toes</th>\n",
       "      <th>date</th>\n",
       "      <th>sex</th>\n",
       "      <th>svl</th>\n",
       "      <th>tl</th>\n",
       "      <th>rtl_orig</th>\n",
       "      <th>mass</th>\n",
       "      <th>paint.mark</th>\n",
       "      <th>location</th>\n",
       "      <th>meters</th>\n",
       "      <th>new.recap</th>\n",
       "      <th>painted</th>\n",
       "      <th>misc</th>\n",
       "      <th>vial</th>\n",
       "      <th>year</th>\n",
       "      <th>rtl</th>\n",
       "      <th>autotomized</th>\n",
       "      <th>new.recap_orig</th>\n",
       "      <th>sighting</th>\n",
       "      <th>review_sex</th>\n",
       "      <th>review_species</th>\n",
       "      <th>review_painted</th>\n",
       "      <th>review_new.recap</th>\n",
       "      <th>review_rtl</th>\n",
       "      <th>forceMale</th>\n",
       "      <th>forceFemale</th>\n",
       "      <th>forceRecap</th>\n",
       "      <th>forceNew</th>\n",
       "      <th>forceSighting</th>\n",
       "      <th>drop_species</th>\n",
       "      <th>drop_morphometrics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>j</td>\n",
       "      <td>1-13-19</td>\n",
       "      <td>2000-03-17T00:00:00Z</td>\n",
       "      <td>f</td>\n",
       "      <td>52.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.2</td>\n",
       "      <td>r1c</td>\n",
       "      <td>1falls</td>\n",
       "      <td>NaN</td>\n",
       "      <td>new</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>new</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>j</td>\n",
       "      <td>1-13-20</td>\n",
       "      <td>2000-03-17T00:00:00Z</td>\n",
       "      <td>m</td>\n",
       "      <td>56.0</td>\n",
       "      <td>77.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.6</td>\n",
       "      <td>r2c</td>\n",
       "      <td>1falls</td>\n",
       "      <td>NaN</td>\n",
       "      <td>new</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>new</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>j</td>\n",
       "      <td>1-14-19</td>\n",
       "      <td>2000-03-17T00:00:00Z</td>\n",
       "      <td>f</td>\n",
       "      <td>57.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.6</td>\n",
       "      <td>r3c</td>\n",
       "      <td>wall on rt side v wall at pine xing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>new</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>new</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>j</td>\n",
       "      <td>1-14-20</td>\n",
       "      <td>2000-03-17T00:00:00Z</td>\n",
       "      <td>f</td>\n",
       "      <td>57.0</td>\n",
       "      <td>79.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.5</td>\n",
       "      <td>r4c</td>\n",
       "      <td>wall on rt side v wall at pine xing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>new</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>new</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>j</td>\n",
       "      <td>3-8</td>\n",
       "      <td>2000-03-17T00:00:00Z</td>\n",
       "      <td>f</td>\n",
       "      <td>82.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>27</td>\n",
       "      <td>17</td>\n",
       "      <td>r5c</td>\n",
       "      <td>oak across from bottom wall at pine xing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>recap</td>\n",
       "      <td>NaN</td>\n",
       "      <td>shed since last recapture</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2000</td>\n",
       "      <td>27.0</td>\n",
       "      <td>True</td>\n",
       "      <td>recap</td>\n",
       "      <td>NaN</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  species     toes                  date sex   svl    tl rtl_orig mass  \\\n",
       "0       j  1-13-19  2000-03-17T00:00:00Z   f  52.0  74.0        0  4.2   \n",
       "1       j  1-13-20  2000-03-17T00:00:00Z   m  56.0  77.0        0  5.6   \n",
       "2       j  1-14-19  2000-03-17T00:00:00Z   f  57.0  81.0        0  6.6   \n",
       "3       j  1-14-20  2000-03-17T00:00:00Z   f  57.0  79.0        0  5.5   \n",
       "4       j      3-8  2000-03-17T00:00:00Z   f  82.0  89.0       27   17   \n",
       "\n",
       "  paint.mark                                  location meters new.recap  \\\n",
       "0        r1c                                    1falls    NaN       new   \n",
       "1        r2c                                    1falls    NaN       new   \n",
       "2        r3c       wall on rt side v wall at pine xing    NaN       new   \n",
       "3        r4c       wall on rt side v wall at pine xing    NaN       new   \n",
       "4        r5c  oak across from bottom wall at pine xing    NaN     recap   \n",
       "\n",
       "  painted                       misc vial  year   rtl  autotomized  \\\n",
       "0     NaN                        NaN  NaN  2000   0.0        False   \n",
       "1     NaN                        NaN  NaN  2000   0.0        False   \n",
       "2     NaN                        NaN  NaN  2000   0.0        False   \n",
       "3     NaN                        NaN  NaN  2000   0.0        False   \n",
       "4     NaN  shed since last recapture  NaN  2000  27.0         True   \n",
       "\n",
       "  new.recap_orig sighting  review_sex  review_species  review_painted  \\\n",
       "0            new      NaN        True           False           False   \n",
       "1            new      NaN        True           False           False   \n",
       "2            new      NaN        True           False           False   \n",
       "3            new      NaN        True           False           False   \n",
       "4          recap      NaN        True           False           False   \n",
       "\n",
       "   review_new.recap  review_rtl  forceMale  forceFemale  forceRecap  forceNew  \\\n",
       "0             False       False      False        False       False     False   \n",
       "1             False       False      False        False       False     False   \n",
       "2             False       False      False        False       False     False   \n",
       "3             False       False      False        False       False     False   \n",
       "4             False       False      False        False       False     False   \n",
       "\n",
       "   forceSighting  drop_species  drop_morphometrics  \n",
       "0          False         False               False  \n",
       "1          False         False               False  \n",
       "2          False         False               False  \n",
       "3          False         False               False  \n",
       "4          False         False               False  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.chdir(sourceDataBig)\n",
    "df=pd.read_csv('mapped-data-all_18-01-08_post_openrefine.csv')\n",
    "\n",
    "os.chdir(outputBig)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "There are 8197 data points in our data set.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nThere are {} data points in our data set.\".format(df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The columns in the data have the following data types:\n",
      "species                object\n",
      "toes                   object\n",
      "date                   object\n",
      "sex                    object\n",
      "svl                   float64\n",
      "tl                    float64\n",
      "rtl_orig               object\n",
      "mass                   object\n",
      "paint.mark             object\n",
      "location               object\n",
      "meters                 object\n",
      "new.recap              object\n",
      "painted                object\n",
      "misc                   object\n",
      "vial                   object\n",
      "year                    int64\n",
      "rtl                   float64\n",
      "autotomized              bool\n",
      "new.recap_orig         object\n",
      "sighting               object\n",
      "review_sex               bool\n",
      "review_species           bool\n",
      "review_painted           bool\n",
      "review_new.recap         bool\n",
      "review_rtl               bool\n",
      "forceMale                bool\n",
      "forceFemale              bool\n",
      "forceRecap               bool\n",
      "forceNew                 bool\n",
      "forceSighting            bool\n",
      "drop_species             bool\n",
      "drop_morphometrics       bool\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nThe columns in the data have the following data types:\\n{}\".format(df.dtypes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correcting class of columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need to add real error handling into these conversion chunks\n",
    "\n",
    "##Convert integer columns to int\n",
    "intCols = ['meters','year']\n",
    "df[intCols]=df[intCols].astype(int,errors='ignore')\n",
    "\n",
    "##Convert numeric columns to numeric\n",
    "numCols = ['svl','tl','rtl','rtl_orig','mass']\n",
    "df[numCols]=df[numCols].apply(pd.to_numeric,errors='coerce')\n",
    "\n",
    "##Convert string columns to str\n",
    "strCols = ['toes','sex','species','vial']\n",
    "df[strCols]=df[strCols].astype(str, errors='ignore')\n",
    "\n",
    "#Convert date to datetime\n",
    "df.loc[df.date==\"NA\"]=np.nan\n",
    "df.date = pd.to_datetime(df.date,errors='coerce')\n",
    "\n",
    "##Convert bool columns to bool\n",
    "boolCols = ['review_sex','review_species','review_painted','review_new.recap',\\\n",
    "            'review_rtl','forceMale','forceFemale','forceRecap','forceNew',\\\n",
    "            'forceSighting','drop_species','drop_morphometrics','autotomized']\n",
    "df[boolCols]=df[boolCols].astype(bool, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After applying the above changes, the data types are as follows:\n",
      "species                       object\n",
      "toes                          object\n",
      "date                  datetime64[ns]\n",
      "sex                           object\n",
      "svl                          float64\n",
      "tl                           float64\n",
      "rtl_orig                     float64\n",
      "mass                         float64\n",
      "paint.mark                    object\n",
      "location                      object\n",
      "meters                        object\n",
      "new.recap                     object\n",
      "painted                       object\n",
      "misc                          object\n",
      "vial                          object\n",
      "year                         float64\n",
      "rtl                          float64\n",
      "autotomized                     bool\n",
      "new.recap_orig                object\n",
      "sighting                      object\n",
      "review_sex                      bool\n",
      "review_species                  bool\n",
      "review_painted                  bool\n",
      "review_new.recap                bool\n",
      "review_rtl                      bool\n",
      "forceMale                       bool\n",
      "forceFemale                     bool\n",
      "forceRecap                      bool\n",
      "forceNew                        bool\n",
      "forceSighting                   bool\n",
      "drop_species                    bool\n",
      "drop_morphometrics              bool\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nAfter applying the above changes, the data types are as follows:\\n{}\".format(df.dtypes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove leading and trailing whitespaces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for col in df:\n",
    "    print(len(col))# returns unique lengths of sex\n",
    "    col=col.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "for col in df:\n",
    "    col=col.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning toes column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we will rename \"toes\" to \"toes_orig\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.rename(columns = {'toes':'toes_orig'},index = str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we create a new column, \"toes\"  for the renamed toes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['toes'] = df.toes_orig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we attempt to identify problem toes name and correct or export for review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pattern1 = \".( {1,}-.|.- {1,}.)\" # toes entries with any number of spaces on either side of a hyphen\n",
    "pattern2 = \".( {,}\\w{,} {1,}).\" # toes entries with space around or between numbers <- the spaces here should be deleted\n",
    "pattern3 = \".(').\"\n",
    "pattern4 = \"./.\"  # entries with '/' <-- need to replace these with '-'\n",
    "pattern5 = \"(\\?{1,})\"#<-- these needs to be investigated\n",
    "pattern6 = \"^\\d{3,}$\" # entries consist of only a single number comprised of at least three digits \n",
    "#<-- these needs to be investigated by checking raw field notes\n",
    "pattern7 = \".(-{2,}).\" # entries which have at least 2 consecutive '-' <- these should be investigated\n",
    "pattern8 = \"^0\" # entries in which single digit numbers have a leading \"0\" <-- Check raw field notes on this too\n",
    "pattern9 = \"a\\w\" #<--handled hyphens should be inserted  between the [ab] and \\w \n",
    "# entries that contain an 'a' or 'b' followed by any character in the set [a-zA-Z0-9_]\n",
    "pattern10 = \"b\\w\" #<--handled hyphens should be inserted  between the [ab] and \\w \n",
    "pattern11 = \"\\wa\" # entries that contain an 'a' or 'b' preceded by any character in the set [a-zA-Z0-9_]\n",
    "pattern12 = \"\\wb\" # entries that contain an 'a' or 'b' preceded by any character in the set [a-zA-Z0-9_]\n",
    "pattern13 = \"[()]\"\n",
    "# remove space before 'a' at end of toes\n",
    "#investigate '\\d-', \n",
    "#'-(*)-', \n",
    "#' (16) ', \n",
    "#'---', <- may not exist in raw data\n",
    "#'\\d- ', \n",
    "#'- \\d', \n",
    "#transcription errors from excel (toes in date format,\n",
    "#'-\\d\\d\\d\\d' <- may not be in the data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll have to change this block if we add or remove toe patterns.\n",
    "This is not ideal and needs to be fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-503630b2c073>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmake_str\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "make_str(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toe_pattern = pd.Series([*range(1,14)]) \n",
    "toe_pattern = make_str(toe_pattern)\n",
    "print(toe_pattern)\n",
    "\n",
    "toe_pattern_descr = pd.Series([pattern1,pattern2,pattern3,pattern4\n",
    "                               ,pattern5,pattern6,pattern7,pattern8\n",
    "                               ,pattern9,pattern10,pattern11,pattern12,pattern13])\n",
    "toe_pattern_descr = toe_pattern_descr.astype(str)\n",
    "print(toe_pattern_descr)\n",
    "\n",
    "toe_pattern_reference = pd.DataFrame({'toe_pattern': toe_pattern,'description':toe_pattern_descr})\n",
    "toe_pattern_reference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first replace the string 'nan' with a null value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.toes=='nan','toes'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see how many of these patterns we need to correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['toe_pattern'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we use a for-loop to label the patterns \n",
    "(there's probably a better way to do this with pandas map or apply, but I'll have to figure this out, for now this is fast enough, but it could make a difference with a larger data set or with more patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(0,toe_pattern_reference.shape[0]):\n",
    "    tmp_pat_num = toe_pattern_reference.iloc[i,0]\n",
    "    tmp_pattern = toe_pattern_reference.iloc[i,1]\n",
    "    df = label_pattern(df,tmp_pat_num,tmp_pattern,'toe_pattern','toes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick summary of the number of observations for each pattern in the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toe_errors =df.toe_pattern.value_counts(dropna=False).reset_index()\\\n",
    ".rename(columns = {'index':'toe_pattern','toe_pattern':'observations'})\n",
    "toe_errors.loc[toe_errors.toe_pattern.isnull(),'toe_pattern'] = 'Not covered by current patterns'\n",
    "toe_errors_desc = toe_errors.merge(toe_pattern_reference,'left',on='toe_pattern')\n",
    "toe_errors_desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's make sure we've accounted for every row in the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accountedRows = toe_errors.observations.sum()\n",
    "totalRows = df.shape[0]\n",
    "notAccountedRows = df.shape[0] - toe_errors.observations.sum()\n",
    "print(\"\\nThere are {} rows accounted for in the patterns (including null values) and there {} rows in the full data set.\\\n",
    "  There are {} rows unaccounted for.\".format(accountedRows,totalRows,notAccountedRows))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### And now we correct these patterns\n",
    "We'll preserve the original toe data in a column called \"toes_orig\" just in case.  We can drop this later, if we are comfortable with the changes.  The new toes will be labeled \"toes\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrections_config = {'01':{'action':'replace','pattern_b':\" \",'replacement':\"\\\"\\\"\"},\n",
    "            '02':{'action':'replace','pattern_b':\" \",'replacement':\"-\"},\n",
    "            '03':{'action':'replace','pattern_b':\"\\'\",'replacement':\"\\\"\\\"\"},\n",
    "            '04':{'action':'replace','pattern_b':\"/\",'replacement':\"-\"},\n",
    "            '05':{'action':'save','pattern_b':np.nan,'replacement':np.nan},\n",
    "            '06':{'action':'save','pattern_b':np.nan,'replacement':np.nan},\n",
    "            '07':{'action':'save','pattern_b':np.nan,'replacement':np.nan},\n",
    "            '08':{'action':'replace','pattern_b':\"^0\",'replacement':\"\\\"\\\"\"},\n",
    "            '09':{'action':'replace','pattern_b':'a','replacement':'-a'},\n",
    "            '10':{'action':'replace','pattern_b':'b','replacement':'-b'},          \n",
    "            '11':{'action':'replace','pattern_b':\"a\",'replacement':\"a-\"},\n",
    "            '12':{'action':'replace','pattern_b':\"b\",'replacement':\"b-\"},\n",
    "            '13':{'action':'replace','pattern_b':\"[()]\",'replacement':\"\\\"\\\"\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "toe_errors_desc['action'] = toe_errors_desc.loc[toe_errors_desc.toe_pattern.str.len()==2].toe_pattern\\\n",
    ".map(lambda x: corrections_config[x]['action'],na_action='ignore')\n",
    "\n",
    "toe_errors_desc['replacement'] = toe_errors_desc.loc[toe_errors_desc.toe_pattern.str.len()==2].toe_pattern\\\n",
    ".map(lambda x: corrections_config[x]['replacement'],na_action='ignore')\n",
    "\n",
    "toe_errors_desc = toe_errors_desc.sort_values('toe_pattern').reset_index(drop=True)\n",
    "toe_errors_desc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,toe_errors_desc.shape[0]):\n",
    "    tmp_pat_num = toe_errors_desc.iloc[i,0]\n",
    "    tmp_pattern = toe_errors_desc.iloc[i,2]\n",
    "    action = toe_errors_desc.iloc[i,3]\n",
    "    tmp_replacement = toe_errors_desc.iloc[i,4]\n",
    "    tmp_x = df.loc[df.toe_pattern==tmp_pat_num,:]\n",
    "    \n",
    "    if action =='save':\n",
    "        tmp_filename = 'pattern'+tmp_pat_num+'.csv'\n",
    "        tmp_x.to_csv(tmp_filename)\n",
    "        print(\"Pattern {} successfully saved to {}.\".format(tmp_pattern,tmp_filename))\n",
    "    if action =='replace':\n",
    "        df.loc[df.toe_pattern==tmp_pat_num,'toes'] = replace_pattern(x=df.loc[df.toe_pattern==tmp_pat_num]\n",
    "                                                                     ,pattern = tmp_pat_num\n",
    "                                                                     ,pattern_b = tmp_pattern\n",
    "                                                                     ,source_col = 'toes'\n",
    "                                                                    ,replacement = tmp_replacement)\n",
    "        print(\"Pattern {} successfully replaced with {}.\".format(tmp_pattern,tmp_replacement))\n",
    "    else:\n",
    "        print(\"No direction provided for pattern {}.  No action was taken.\".format(tmp_pattern))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we confirm that the patterns we expect to have eliminated have indeed been eliminated from the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(0,toe_pattern_reference.shape[0]):\n",
    "    tmp_pattern = str(toe_pattern_reference.iloc[i,1])\n",
    "    report_pattern(df,tmp_pattern,'toes','Post-Correction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning Sex column\n",
    "Next we move on to cleaning the \"sex\" column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we want to get an idea of the types of problems in the sex column.  We start by striping leading and trailing whitespaces.  You can see here that there were none in the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.sex.str.len().unique())# returns unique lengths of sex\n",
    "df.sex=df.sex.str.strip()\n",
    "print(df.sex.str.len().unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify non \"m\" or \"f\" values and their frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "patterns_sex=\"m|f|NA\"\n",
    "non_matches=df.sex.loc[df.sex.str.match(patterns_sex)!=True]\n",
    "print(\"\\nThere are {} entries for sex which do not match the patterns {}:\"\\\n",
    "      .format(non_matches.shape[0],patterns_sex.split(\"|\")))\n",
    "non_matches.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify values to convert to NA, m, or f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sex2NA=['adult','juv','nan']\n",
    "sex2m=['unm']\n",
    "df.loc[df.sex.isin(sex2NA)==True]\n",
    "print(df.sex.loc[df.sex.isin(sex2NA)==True].count())\n",
    "print(df.sex.loc[df.sex.isin(sex2m)==True].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert the values to NA or m, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.loc[df.sex.isin(sex2m)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[df.sex.isin(sex2NA),'sex']=np.nan\n",
    "df.loc[df.sex.isin(sex2m),'sex']='m'\n",
    "print(df.sex.loc[df.sex.isin(sex2NA)==True].count())\n",
    "print(df.sex.loc[df.sex.isin(sex2m)==True].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set all remaining species and sex with \"?\" to NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[(df.species.str.contains('\\?')) & (df.species.notnull()),'species'] = np.nan\n",
    "df.loc[(df.sex.str.contains('\\?')) & (df.sex.notnull()),'sex'] = np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning autotmized column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "autotomyDict = {False:'intact',True:'autotomized'}\n",
    "\n",
    "df.loc[:,'autotomized'] = df.loc[:,'autotomized'].map(autotomyDict)\n",
    "df.autotomized.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning new.recap column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#try using a dict to do thing more efficiently\n",
    "newRecapKeep = ['recap', 'new', 'r', 'n']\n",
    "new = ['new','n']\n",
    "recap = ['recap','r']\n",
    "df.loc[~df['new.recap'].isin(newRecapKeep),'new.recap'] = np.nan\n",
    "df.loc[df['new.recap'].isin(new),'new.recap'] = 'new'\n",
    "df.loc[df['new.recap'].isin(recap),'new.recap'] = 'recap'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tl_svl and mass_svl\n",
    "df['tl_svl']=(df.tl/df.svl)\n",
    "df['mass_svl']=(df.mass/df.svl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial attempt to assign lizard numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sortable = lizsort(df, path = 'S:\\\\Chris\\\\TailDemography\\\\data')\n",
    "    \n",
    "sortable = mindate(sortable)\n",
    "sortable = smallest(sortable)\n",
    "tmp_sort = validate(sortable)\n",
    "sortable = tmp_sort['val_data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Second attempt to assign lizard numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_val = mindate(tmp_sort['n_val_data'])\n",
    "n_val = smallest(n_val)\n",
    "df_numbered = validate(n_val)['val_data']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying the output data frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numbered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QC of lizard numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify individuals that have same species and toes, but different sex for review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.merge(df.groupby(['species','toes']).sex.nunique().reset_index().rename(columns = {'sex':'sex_count'})\\\n",
    "         ,how = 'inner', on = ['species','toes'])\n",
    "print(df.loc[df.sex_count>1,:].shape[0])\n",
    "df.loc[df.sex_count>1,:].to_csv('entries flagged with same species and toes diff sex.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.groupby(['species','toes']).sex.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Lizard Numbers in the sample range from {} to {}.\"\\\n",
    "      .format(df_numbered.liznumber.min(),df_numbered.liznumber.max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "possibleLizNum = set(range(int(df_numbered.liznumber.min()),int(df_numbered.liznumber.max())))\n",
    "actualLizNum = set(pd.Series(df_numbered.liznumber.unique()).dropna().apply(int))\n",
    "print(\"\\nThere are {} entries.  There are {} unique lizard numbers.\\\n",
    "\\n\\nThe liznumber ranges from {} to {}.\"\\\n",
    "  .format(df_numbered.shape[0],len(df_numbered.liznumber.unique())\\\n",
    "          ,df_numbered.liznumber.min(),df_numbered.liznumber.max()))\n",
    "\n",
    "missingLizNum = possibleLizNum - actualLizNum\n",
    "if len(missingLizNum)>0:\n",
    "    print(\"\\n\\nThe following numbers are not assigned to a lizard:\\n{}\"\\\n",
    "      .format(missingLizNum))\n",
    "else:\n",
    "    print(\"\\n\\nThere are no numbers which were not assigned.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add additional columns\n",
    "- *daysSinceCapture* [int]:identifies the number of days since the animal was captured\n",
    "- *capture* [int]: identifies the number of times an animal has been captured prior to an entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numbered.loc[:,'daysSinceCapture'] = (df_numbered.date - df_numbered.initialCaptureDate).dt.days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to QC this\n",
    "df_numbered['capture'] = df_numbered.sort_values(['liznumber','date'])\\\n",
    ".groupby(['liznumber']).daysSinceCapture.cumcount()+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numbered.species.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_numbered.loc[df_numbered.species.isin(['j','v'])].groupby('capture').capture.count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [go.Histogram(x = df_numbered.groupby('liznumber').capture.max())]\n",
    "py.iplot(data, filename = 'Frequency of Captures in Crystal Creek 2000 - 2017')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lizards = [go.Scatter(x = df_numbered.liznumber,\n",
    "                   y = df_numbered.groupby('liznumber').daysSinceCapture.max(), \n",
    "                     mode = 'markers')]\n",
    "# year1 = [go.scatter.Line(y = 365)]\n",
    "# year2 = [go.scatter.Line(y = 365*2)]\n",
    "# year3 = [go.scatter.Line(y = 365*3)]\n",
    "# year4 = [go.scatter.Line(y = 365*4)]\n",
    "# year5 = [go.scatter.Line(y = 365*5)]\n",
    "# year6 = [go.scatter.Line(y = 365*6)]\n",
    "# year7 = [go.scatter.Line(y = 365*7)]\n",
    "# year8 = [go.scatter.Line(y = 365*8)]\n",
    "\n",
    "# data = [lizards, year1, year2, year3, year4, year5, year6, year7, year8]\n",
    "data = lizards\n",
    "layout = go.Layout(\n",
    "    title = 'Days Since Initial Capture in Crystal Creek 2000 - 2017',\n",
    "        titlefont = dict(\n",
    "            size = 20),\n",
    "    xaxis = dict(\n",
    "            title='Lizard Number',\n",
    "            titlefont=dict(\n",
    "                size=18)),\n",
    "    yaxis = dict(\n",
    "            title='Greatest Number of Days Since<br> Initial Capture',\n",
    "            titlefont=dict(\n",
    "                size=18)))\n",
    "\n",
    "fig = go.Figure(data=data, layout=layout)\n",
    "py.iplot(fig, filename = 'Days Since Initial Capture in Crystal Creek 2000 - 2017')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfF = df_numbered.loc[df_numbered.sex =='f']\n",
    "dfM = df_numbered.loc[df_numbered.sex =='m']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "females = go.Scatter(\n",
    "    x = dfF.liznumber,\n",
    "    y = dfF.groupby('liznumber').daysSinceCapture.max(),\n",
    "    name = 'females',\n",
    "    mode = 'markers',\n",
    "    marker = dict(\n",
    "        color = 'rgba(152, 0, 0, .8)',\n",
    "        opacity = 0.75,\n",
    "        line = dict(\n",
    "            width = 2,\n",
    "            color = 'rgb(0, 0, 0)'\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "males = go.Scatter(\n",
    "    x = dfM.liznumber,\n",
    "    y = dfM.groupby('liznumber').daysSinceCapture.max(),\n",
    "    name = 'males',\n",
    "    mode = 'markers',\n",
    "    marker = dict(\n",
    "        color = 'rgba(255, 182, 193, .9)',\n",
    "        opacity = 0.75,\n",
    "        line = dict(\n",
    "            width = 2,\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "data = [females, males]\n",
    "\n",
    "layout = dict(title = 'Days Since Initial Capture in Crystal Creek 2000 - 2017 By Sex',\n",
    "              yaxis = dict(\n",
    "                  title='Greatest Number of Days Since<br> Initial Capture',\n",
    "                  titlefont=dict(\n",
    "                      size=18)\n",
    "              ),\n",
    "              xaxis = dict(zeroline = False)\n",
    "             )\n",
    "\n",
    "fig = dict(data=data, layout=layout)\n",
    "py.iplot(fig, filename='Days Since Initial Capture in Crystal Creek 2000 - 2017 By Sex')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "males = go.Histogram(x = df_numbered.loc[df.sex == 'm','capture'],opacity= 0.75,name='males')\n",
    "females = go.Histogram(x = df_numbered.loc[df.sex == 'f','capture'], opacity= 0.75, name = 'females')\n",
    "data = [males,females]\n",
    "py.iplot(data, filename = 'Frequency of Captures by Sex in Crystal Creek 2000 - 2017')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## QC of Capture number and Recap status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numbered.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recapQuestion=df_numbered.loc[(df_numbered.capture==1 )& (df_numbered[\"new.recap\"]=='recap'),:]\n",
    "print(\"There are {} instances in rows for which a lizard appears to have only one capture, but is listed as a recap.\\\n",
    "The distribution of these across years in the sample is as follows:\\n{}.\"\\\n",
    "      .format(recapQuestion.shape[0],recapQuestion.year.value_counts()))\n",
    "recapQuestion.to_csv(\"Questionable recaptures.csv\")#These individuals need to be rechecked in the raw notes\n",
    "recapQuestion.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recapQuestion.loc[recapQuestion.svl<54,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we export the cleaned data to a csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_numbered = df_numbered.rename(index = str, columns = {'new.recap':'newRecap'})\n",
    "qc_drop_cols = df_numbered.columns[df_numbered.columns.str.contains('force|drop')]\n",
    "df_full = df_numbered.drop(qc_drop_cols,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "timestamp = (pd.to_datetime('now')-pd.Timedelta(hours=4))\n",
    "timestamp = str(timestamp).replace(':','_')\n",
    "#path=''C:\\\\Users\\\\Christopher\\\\Google Drive\\\\TailDemography\\\\outputFiles\\\\''\n",
    "# path=outputBig\n",
    "filename = 'cleaned CC data 2000-2017_' + timestamp+ '.csv'\n",
    "# filename = path + '/cleaned CC data 2000-2017' + '.csv'\n",
    "df_full.to_csv(filename,index = False)\n",
    "filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
